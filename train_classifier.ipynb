{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "from numpy.random import seed\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from DataGenerator import DataGenerator\n",
    "from i3d_inception import *\n",
    "\n",
    "# Helper libraries\n",
    "seed(1)\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.layers import (Input, Conv2D, MaxPooling2D, Flatten, Activation, Dense, Dropout, ZeroPadding2D)\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedShuffleSplit\n",
    "from keras.layers.advanced_activations import ELU\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE VARIABLES ---\n",
    "data_folder = r'C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\kinetics-i3d\\data\\MAA' \n",
    "#mean_file = 'flow_mean.mat'  # Used as a normalisation for the input of the network\n",
    "\n",
    "save_features = True  # Boolean flag if we save features in h5py\n",
    "save_plots = True\n",
    "\n",
    "# Set to 'True' if you want to restore a previous trained models\n",
    "# Training is skipped and test is done\n",
    "use_checkpoint = False # Set to True or False\n",
    "# --------------------------\n",
    "\n",
    "best_model_path = 'models/'\n",
    "plots_folder = 'plots/'\n",
    "checkpoint_path = 'models/fold_'\n",
    "\n",
    "features_file = 'features_MAA.h5'\n",
    "labels_file = 'labels_MAA.h5'\n",
    "features_key = 'features'\n",
    "labels_key = 'labels'\n",
    "\n",
    "gpu_num = 1 \n",
    "num_features = [None, 7, 1, 1, 1024]  # Specific dimension of features for 64-frame clips\n",
    "batch_norm = False\n",
    "learning_rate = 0.1\n",
    "mini_batch_size = 4\n",
    "weight_0 = 1.0  # A higher weight of 0 prioritizes learning in class 0\n",
    "epochs = 100\n",
    "dropout_prob=0.0\n",
    "\n",
    "weights = 'rgb_imagenet_and_kinetics'\n",
    "name = 'train_classifier'\n",
    "\n",
    "# Name of the experiment\n",
    "exp = 'slips_lr{}_batchs{}_batchnorm{}_w0_{}_{}_{}'.format(learning_rate,\n",
    "                                                           mini_batch_size,\n",
    "                                                           batch_norm,\n",
    "                                                           weight_0, \n",
    "                                                           name,\n",
    "                                                           weights)\n",
    "\n",
    "# Input dimensions\n",
    "NUM_FRAMES = 64\n",
    "FRAME_HEIGHT = 224\n",
    "FRAME_WIDTH = 224\n",
    "NUM_RGB_CHANNELS = 3\n",
    "NUM_CLASSES = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions \n",
    "def plot_training_info(case, metrics, save, history):\n",
    "    \"\"\"\n",
    "    Function to create plots for train and validation loss and accuracy\n",
    "    Input:\n",
    "    * case: name for the plot, an 'accuracy.png' or 'loss.png' will be concatenated after the name.\n",
    "    * metrics: list of metrics to store: 'loss' and/or 'accuracy'\n",
    "    * save: boolean to store the plots or only show them.\n",
    "    * history: History object returned by the Keras fit function.\n",
    "    \"\"\"\n",
    "    plt.ioff()\n",
    "    if 'accuracy' in metrics:\n",
    "        fig = plt.figure()\n",
    "        plt.plot(history['acc'])\n",
    "        plt.plot(history['val_acc'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        if save:\n",
    "            plt.savefig(case + 'accuracy.png')\n",
    "            plt.gcf().clear()\n",
    "        else:\n",
    "            plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "    # summarize history for loss\n",
    "    if 'loss' in metrics:\n",
    "        fig = plt.figure()\n",
    "        plt.plot(history['loss'])\n",
    "        plt.plot(history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        # plt.ylim(1e-3, 1e-2)\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        if save:\n",
    "            plt.savefig(case + 'loss.png')\n",
    "            plt.gcf().clear()\n",
    "        else:\n",
    "            plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "def list_data():\n",
    "    \"\"\"\n",
    "    Function to list existing data set by filename and label \n",
    "    \"\"\"\n",
    "    vids = {'pass': [], 'fail': []}\n",
    "    \n",
    "    for file in os.listdir(data_folder):\n",
    "        if not file.lower().endswith('.npy'):\n",
    "            continue\n",
    "        else:\n",
    "            file_dir = os.path.join(data_folder, file)\n",
    "            ID = file_dir.split('\\\\')[-1].rstrip('.npy')\n",
    "            # Classify\n",
    "            result = ID.split('_')[2][1]\n",
    "            if result == \"P\": vids[\"pass\"].append(ID)\n",
    "            else: vids[\"fail\"].append(ID)\n",
    "    return vids\n",
    "\n",
    "\n",
    "def saveFeatures(feature_extractor,\n",
    "                 features_file,\n",
    "                 labels_file,\n",
    "                 features_key,\n",
    "                 labels_key):\n",
    "    \"\"\"\n",
    "    Function to load the optical flow stacks, do a feed-forward through the feature extractor and store the\n",
    "    output feature vectors in the file 'features_file' and the labels in 'labels_file'.\n",
    "    Input:\n",
    "    * feature_extractor: model without the top layer, which is the classifoer\n",
    "    * features_file: path to the hdf5 file where the extracted features are going to be stored\n",
    "    * labels_file: path to the hdf5 file where the labels of the features are going to be stored\n",
    "    * features_key: name of the key for the hdf5 file to store the features\n",
    "    * labels_key: name of the key for the hdf5 file to store the labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Fill the IDs and classes arrays\n",
    "    classes = list_data()\n",
    "    class0, class1 = classes['fail'], classes['pass']\n",
    "    num_samples = len(class0) + len(class1)\n",
    "    num_features[0] = num_samples\n",
    "    \n",
    "    # File to store the extracted features and datasets to store them\n",
    "    # IMPORTANT NOTE: 'w' mode totally erases previous data\n",
    "    # Write files in h5py format\n",
    "    h5features = h5py.File(features_file, 'w')\n",
    "    h5labels = h5py.File(labels_file, 'w')\n",
    "    \n",
    "    # Create data sets\n",
    "    dataset_features = h5features.create_dataset(features_key,\n",
    "                                                 shape=num_features,\n",
    "                                                 dtype='float64')\n",
    "    dataset_labels = h5labels.create_dataset(labels_key,\n",
    "                                             shape=(num_samples, 1),\n",
    "                                             dtype='float64')\n",
    "\n",
    "    # Process class 0 \n",
    "    gen = DataGenerator(class0, np.zeros(len(class0)), 1)\n",
    "    for i in range(len(class0)):\n",
    "                        \n",
    "        rgb_images, rgb_labels = gen.__getitem__(i)\n",
    "        predictions = feature_extractor.predict(rgb_images)\n",
    "\n",
    "        dataset_features[i, :] = predictions\n",
    "        dataset_labels[i, :] = 0\n",
    "                \n",
    "        del rgb_images, rgb_labels\n",
    "        gc.collect()\n",
    "        \n",
    "    # Process class 1\n",
    "    gen = DataGenerator(class1, np.ones(len(class1)), 1)\n",
    "    for i in range(len(class0), num_samples):\n",
    "        \n",
    "        rgb_images, rgb_labels = gen.__getitem__(i)        \n",
    "        prediction = feature_extractor.predict(rgb_images)\n",
    "\n",
    "        dataset_features[i, :] = predictions\n",
    "        dataset_labels[i, :]= 1\n",
    "\n",
    "        del rgb_images, rgb_labels\n",
    "        gc.collect()\n",
    "\n",
    "    h5features.close()\n",
    "    h5labels.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer \n",
    "def main():\n",
    "    # ========================================================================\n",
    "    # I3D ARCHITECTURE\n",
    "    # ========================================================================\n",
    "    model = Inception_Inflated3d(\n",
    "        include_top=False,\n",
    "        weights='rgb_imagenet_and_kinetics',\n",
    "        input_shape=(NUM_FRAMES, FRAME_HEIGHT, FRAME_WIDTH, NUM_RGB_CHANNELS),\n",
    "        classes=NUM_CLASSES)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # FEATURE EXTRACTION\n",
    "    # ========================================================================\n",
    "    if save_features:\n",
    "        saveFeatures(model, features_file,\n",
    "                     labels_file, features_key,\n",
    "                     labels_key)\n",
    "\n",
    "    # ========================================================================\n",
    "    # TRAINING\n",
    "    # ========================================================================    \n",
    "    adam = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999,\n",
    "                epsilon=1e-08)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    do_training = True\n",
    "    compute_metrics = True\n",
    "    threshold = 0.5\n",
    "\n",
    "    if do_training:\n",
    "        # Import data\n",
    "        h5features = h5py.File(features_file, 'r')\n",
    "        h5labels = h5py.File(labels_file, 'r')\n",
    "        \n",
    "        # X_full will contain all the feature vectors extracted\n",
    "        X_full = h5features[features_key]\n",
    "        _y_full = np.asarray(h5labels[labels_key])\n",
    "        \n",
    "        # Indices of 0 and 1 in the data set\n",
    "        zeroes_full = np.asarray(np.where(_y_full == 0)[0])\n",
    "        ones_full = np.asarray(np.where(_y_full == 1)[0])\n",
    "        zeroes_full.sort()\n",
    "        ones_full.sort()\n",
    "\n",
    "        # Traditional Machine Learning methodology\n",
    "        # Method get_n_splits() returns the number of splits \n",
    "        kf_0 = KFold(n_splits=5, shuffle=True)\n",
    "        kf_0.get_n_splits(X_full[zeroes_full, ...])\n",
    "\n",
    "        kf_1 = KFold(n_splits=5, shuffle=True)\n",
    "        kf_1.get_n_splits(X_full[ones_full, ...])\n",
    "\n",
    "        sensitivities = []\n",
    "        specificities = []\n",
    "        fars = []\n",
    "        mdrs = []\n",
    "        accuracies = []\n",
    "\n",
    "        fold_number = 1\n",
    "        \n",
    "        # CROSS-VALIDATION: Stratified partition of the dataset into train/test sets\n",
    "        for ((train_index_0, test_index_0),\n",
    "             (train_index_1, test_index_1)) in zip(\n",
    "            kf_0.split(X_full[zeroes_full, ...]),\n",
    "            kf_1.split(X_full[ones_full, ...])\n",
    "        ):\n",
    "            \n",
    "            train_index_0 = np.asarray(train_index_0)\n",
    "            test_index_0 = np.asarray(test_index_0)\n",
    "            train_index_1 = np.asarray(train_index_1)\n",
    "            test_index_1 = np.asarray(test_index_1)\n",
    "\n",
    "            # Train and Test Set\n",
    "            X = np.concatenate((X_full[zeroes_full, ...][train_index_0, ...],\n",
    "                                X_full[ones_full, ...][train_index_1, ...]))\n",
    "            _y = np.concatenate((_y_full[zeroes_full, ...][train_index_0, ...],\n",
    "                                 _y_full[ones_full, ...][train_index_1, ...]))\n",
    "            X2 = np.concatenate((X_full[zeroes_full, ...][test_index_0, ...],\n",
    "                                 X_full[ones_full, ...][test_index_1, ...]))\n",
    "            _y2 = np.concatenate((_y_full[zeroes_full, ...][test_index_0, ...],\n",
    "                                  _y_full[ones_full, ...][test_index_1, ...]))\n",
    "\n",
    "            # Create a validation subset from the training set\n",
    "            val_size = 0.2\n",
    "            \n",
    "            zeroes = np.asarray(np.where(_y == 0)[0])\n",
    "            ones = np.asarray(np.where(_y == 1)[0])\n",
    "            \n",
    "            zeroes.sort()\n",
    "            ones.sort()\n",
    "\n",
    "            trainval_split_0 = StratifiedShuffleSplit(n_splits=1,\n",
    "                                                      test_size=val_size / 2,\n",
    "                                                      random_state=None)\n",
    "            indices_0 = trainval_split_0.split(X[zeroes, ...],\n",
    "                                               np.argmax(_y[zeroes, ...], 1))\n",
    "            trainval_split_1 = StratifiedShuffleSplit(n_splits=1,\n",
    "                                                      test_size=val_size / 2,\n",
    "                                                      random_state=None)\n",
    "            indices_1 = trainval_split_1.split(X[ones, ...],\n",
    "                                               np.argmax(_y[ones, ...], 1))\n",
    "            \n",
    "            train_indices_0, val_indices_0 = indices_0.__next__()\n",
    "            train_indices_1, val_indices_1 = indices_1.__next__()\n",
    "\n",
    "            X_train = np.concatenate([X[zeroes, ...][train_indices_0, ...],\n",
    "                                      X[ones, ...][train_indices_1, ...]], axis=0)\n",
    "            y_train = np.concatenate([_y[zeroes, ...][train_indices_0, ...],\n",
    "                                      _y[ones, ...][train_indices_1, ...]], axis=0)\n",
    "            X_val = np.concatenate([X[zeroes, ...][val_indices_0, ...],\n",
    "                                    X[ones, ...][val_indices_1, ...]], axis=0)\n",
    "            y_val = np.concatenate([_y[zeroes, ...][val_indices_0, ...],\n",
    "                                    _y[ones, ...][val_indices_1, ...]], axis=0)\n",
    "           \n",
    "            # ==================== CLASSIFIER ========================\n",
    "\n",
    "            extracted_features = Input(shape=(7, 1, 1, 1024,), dtype='float32', name='input')\n",
    "\n",
    "            # Batch size of 1 does not need normalization\n",
    "            if batch_norm:\n",
    "                x = BatchNormalization(axis=-1, momentum=0.99,\n",
    "                                       epsilon=0.001)(extracted_features)\n",
    "\n",
    "            # Classification block\n",
    "            x = extracted_features\n",
    "            # x = AveragePooling3D((2, 7, 7), strides=(1, 1, 1), padding='valid', name='global_avg_pool')(x)\n",
    "            x = Dropout(dropout_prob)(x)\n",
    "\n",
    "            x = conv3d_bn(x, NUM_CLASSES, 1, 1, 1, padding='same', \n",
    "                    use_bias=True, use_activation_fn=False, use_bn=False, name='Conv3d_6a_1x1')\n",
    "\n",
    "            num_frames_remaining = int(x.shape[1])\n",
    "            x = Reshape((num_frames_remaining, NUM_CLASSES))(x)\n",
    "\n",
    "            # logits (raw scores for each class)\n",
    "            x = Lambda(lambda x: K.mean(x, axis=1, keepdims=False),\n",
    "                       output_shape=lambda s: (s[0], s[2]))(x)\n",
    "\n",
    "            # if not endpoint_logit\n",
    "            x = Activation('softmax', name='prediction')(x)\n",
    "\n",
    "            # Compile\n",
    "            classifier = Model(input=extracted_features, output=x, name='classifier')\n",
    "            fold_best_model_path = best_model_path + exp + '_MAA_fold_{}.h5'.format(fold_number)\n",
    "            classifier.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "            if not use_checkpoint:\n",
    "                # ==================== TRAINING ========================\n",
    "                # weighting of each class: only the fall class gets\n",
    "                # a different weight\n",
    "                class_weight = {0: weight_0, 1: 1}\n",
    "\n",
    "                # callback definition\n",
    "                metric = 'val_loss'\n",
    "                e = EarlyStopping(monitor=metric, min_delta=0, patience=20,\n",
    "                                  mode='auto')\n",
    "                c = ModelCheckpoint(fold_best_model_path, monitor=metric,\n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=False, mode='auto')\n",
    "                callbacks = [e, c]\n",
    "\n",
    "                # Batch training\n",
    "                if mini_batch_size == 0:\n",
    "                    history = classifier.fit(X_train, y_train,\n",
    "                                             validation_data=(X_val, y_val),\n",
    "                                             batch_size=X_train.shape[0],\n",
    "                                             nb_epoch=epochs,\n",
    "                                             shuffle='batch',\n",
    "                                             class_weight=class_weight,\n",
    "                                             callbacks=callbacks)\n",
    "                else:\n",
    "                    history = classifier.fit(X_train, y_train,\n",
    "                                             validation_data=(X_val, y_val),\n",
    "                                             batch_size=mini_batch_size,\n",
    "                                             nb_epoch=epochs,\n",
    "                                             shuffle='batch',\n",
    "                                             class_weight=class_weight,\n",
    "                                             callbacks=callbacks)\n",
    "\n",
    "                plot_training_info(plots_folder + exp, ['accuracy', 'loss'],\n",
    "                                   save_plots, history.history)\n",
    "\n",
    "                classifier = load_model(fold_best_model_path)\n",
    "\n",
    "                # Use full training set (training+validation)\n",
    "                X_train = np.concatenate((X_train, X_val), axis=0)\n",
    "                y_train = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "                if mini_batch_size == 0:\n",
    "                    history = classifier.fit(X_train, y_train,\n",
    "                                             batch_size=X_train.shape[0],\n",
    "                                             nb_epoch=1,\n",
    "                                             shuffle='batch',\n",
    "                                             class_weight=class_weight)\n",
    "                else:\n",
    "                    history = classifier.fit(X_train, y_train,\n",
    "                                             batch_size=mini_batch_size,\n",
    "                                             nb_epoch=1,\n",
    "                                             shuffle='batch',\n",
    "                                             class_weight=class_weight)\n",
    "\n",
    "                classifier.save(fold_best_model_path)\n",
    "\n",
    "            # ==================== EVALUATION ========================\n",
    "            # Load best model\n",
    "            print('Model loaded from checkpoint')\n",
    "\n",
    "            classifier = load_model(fold_best_model_path)\n",
    "\n",
    "\n",
    "            if compute_metrics:\n",
    "                predicted = classifier.predict(np.asarray(X2))\n",
    "                predicted = predicted[:,1]\n",
    "\n",
    "                # Array of predictions 0/1\n",
    "                predicted = np.asarray(predicted).astype(int)\n",
    "                \n",
    "                # Compute metrics and print them\n",
    "                cm = confusion_matrix(_y2, predicted, labels=[0, 1])\n",
    "                tp = cm[0][0]\n",
    "                fn = cm[0][1]\n",
    "                fp = cm[1][0]\n",
    "                tn = cm[1][1]\n",
    "                tpr = tp / float(tp + fn)\n",
    "                fpr = fp / float(fp + tn)\n",
    "                fnr = fn / float(fn + tp)\n",
    "                tnr = tn / float(tn + fp)\n",
    "                precision = tp / float(tp + fp)\n",
    "                recall = tp / float(tp + fn)\n",
    "                specificity = tn / float(tn + fp)\n",
    "                f1 = 2 * float(precision * recall) / float(precision + recall)\n",
    "                accuracy = accuracy_score(_y2, predicted)\n",
    "\n",
    "                print('\\n')\n",
    "                print('FOLD {} results:'.format(fold_number))\n",
    "                print('TP: {}, TN: {}, FP: {}, FN: {}'.format(tp, tn, fp, fn))\n",
    "                print('TPR: {}, TNR: {}, FPR: {}, FNR: {}'.format(\n",
    "                    tpr, tnr, fpr, fnr))\n",
    "                print('Sensitivity/Recall: {}'.format(recall))\n",
    "                print('Specificity: {}'.format(specificity))\n",
    "                print('Precision: {}'.format(precision))\n",
    "                print('F1-measure: {}'.format(f1))\n",
    "                print('Accuracy: {}'.format(accuracy))\n",
    "                print('\\n')\n",
    "\n",
    "                fold_number += 1\n",
    "\n",
    "                # Store the metrics for this epoch\n",
    "                sensitivities.append(tp / float(tp + fn))\n",
    "                specificities.append(tn / float(tn + fp))\n",
    "                fars.append(fpr)\n",
    "                mdrs.append(fnr)\n",
    "                accuracies.append(accuracy)\n",
    "\n",
    "\n",
    "    print('5-FOLD CROSS-VALIDATION RESULTS ===================')\n",
    "    print(\"Sensitivity: %.2f (+/- %.2f)\" % (np.mean(sensitivities), np.std(sensitivities)))\n",
    "    print(\"Specificity: %.2f (+/- %.2f)\" % (np.mean(specificities), np.std(specificities)))\n",
    "    print(\"FAR: %.2f (+/- %.2f)\" % (np.mean(fars), np.std(fars)))  # False alarm rates \n",
    "    print(\"MDR: %.2f (+/- %.2f)\" % (np.mean(mdrs), np.std(mdrs)))  # Missed detection rates\n",
    "    print(\"Accuracy: %.2f (+/- %.2f)\" % (np.mean(accuracies), np.std(accuracies)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:145: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"classifier\", inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:181: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 77 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 1s 13ms/step - loss: 8.2644 - acc: 0.4675 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7451 - acc: 0.5195 - val_loss: 8.0590 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:203: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7.7811 - acc: 0.5172\n",
      "Model loaded from checkpoint\n",
      "\n",
      "\n",
      "FOLD 1 results:\n",
      "TP: 12, TN: 0, FP: 11, FN: 0\n",
      "TPR: 1.0, TNR: 0.0, FPR: 1.0, FNR: 0.0\n",
      "Sensitivity/Recall: 1.0\n",
      "Specificity: 0.0\n",
      "Precision: 0.5217391304347826\n",
      "F1-measure: 0.6857142857142856\n",
      "Accuracy: 0.5217391304347826\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:145: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"classifier\", inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:181: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 77 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.3730 - acc: 0.4805 - val_loss: 8.0590 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:203: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.3369 - acc: 0.4828\n",
      "Model loaded from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:231: RuntimeWarning: invalid value encountered in true_divide\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:145: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"classifier\", inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:181: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "FOLD 2 results:\n",
      "TP: 0, TN: 11, FP: 0, FN: 12\n",
      "TPR: 0.0, TNR: 1.0, FPR: 0.0, FNR: 1.0\n",
      "Sensitivity/Recall: 0.0\n",
      "Specificity: 1.0\n",
      "Precision: nan\n",
      "F1-measure: nan\n",
      "Accuracy: 0.4782608695652174\n",
      "\n",
      "\n",
      "Train on 78 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 7.6458 - acc: 0.5256 - val_loss: 8.0590 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:203: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 7.6927 - acc: 0.5227\n",
      "Model loaded from checkpoint\n",
      "\n",
      "\n",
      "FOLD 3 results:\n",
      "TP: 11, TN: 0, FP: 11, FN: 0\n",
      "TPR: 1.0, TNR: 0.0, FPR: 1.0, FNR: 0.0\n",
      "Sensitivity/Recall: 1.0\n",
      "Specificity: 0.0\n",
      "Precision: 0.5\n",
      "F1-measure: 0.6666666666666666\n",
      "Accuracy: 0.5\n",
      "\n",
      "\n",
      "Train on 79 samples, validate on 10 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:145: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"classifier\", inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:181: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 1s 16ms/step - loss: 8.0936 - acc: 0.4684 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:203: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 7.7874 - acc: 0.5169\n",
      "Model loaded from checkpoint\n",
      "\n",
      "\n",
      "FOLD 4 results:\n",
      "TP: 11, TN: 0, FP: 10, FN: 0\n",
      "TPR: 1.0, TNR: 0.0, FPR: 1.0, FNR: 0.0\n",
      "Sensitivity/Recall: 1.0\n",
      "Specificity: 0.0\n",
      "Precision: 0.5238095238095238\n",
      "F1-measure: 0.6875000000000001\n",
      "Accuracy: 0.5238095238095238\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:145: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"classifier\", inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:181: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 7.7531 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 7.7530 - acc: 0.5190 - val_loss: 8.0590 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:203: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 7.7874 - acc: 0.5169\n",
      "Model loaded from checkpoint\n",
      "\n",
      "\n",
      "FOLD 5 results:\n",
      "TP: 11, TN: 0, FP: 10, FN: 0\n",
      "TPR: 1.0, TNR: 0.0, FPR: 1.0, FNR: 0.0\n",
      "Sensitivity/Recall: 1.0\n",
      "Specificity: 0.0\n",
      "Precision: 0.5238095238095238\n",
      "F1-measure: 0.6875000000000001\n",
      "Accuracy: 0.5238095238095238\n",
      "\n",
      "\n",
      "5-FOLD CROSS-VALIDATION RESULTS ===================\n",
      "Sensitivity: 0.80 (+/- 0.40)\n",
      "Specificity: 0.20 (+/- 0.40)\n",
      "FAR: 0.80 (+/- 0.40)\n",
      "MDR: 0.20 (+/- 0.40)\n",
      "Accuracy: 0.51 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    if not os.path.exists(best_model_path):\n",
    "        os.makedirs(best_model_path)\n",
    "    if not os.path.exists(plots_folder):\n",
    "        os.makedirs(plots_folder)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous\n",
    "def miscellaneous():\n",
    "    model = Inception_Inflated3d(\n",
    "            include_top=False,\n",
    "            weights='rgb_imagenet_and_kinetics',\n",
    "            input_shape=(NUM_FRAMES, FRAME_HEIGHT, FRAME_WIDTH, NUM_RGB_CHANNELS),\n",
    "            classes=NUM_CLASSES)\n",
    "\n",
    "    rgb_sample = np.load(r\"C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\kinetics-i3d\\data\\MAA\\idapt518_sub253_DF_10-18-15.npy\")\n",
    "    rgb_sample = np.expand_dims(rgb_sample, axis=0)\n",
    "    rgb_logits = model.predict(rgb_sample)\n",
    "    print(rgb_logits.shape)\n",
    "    \n",
    "# miscellaneous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-kinetics-i3d",
   "language": "python",
   "name": "keras-kinetics-i3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

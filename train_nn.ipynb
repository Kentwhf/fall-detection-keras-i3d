{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "from numpy.random import seed\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from DataGenerator import DataGenerator\n",
    "from i3d_inception import *\n",
    "\n",
    "# Helper libraries\n",
    "seed(4)\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.layers import (Input, Conv2D, MaxPooling2D, Flatten, Activation, Dense, Dropout, ZeroPadding2D)\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, auc, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedShuffleSplit\n",
    "from scipy import interp\n",
    "from keras.layers.advanced_activations import ELU\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import get_session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE VARIABLES ---\n",
    "data_folder = r'C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\Fall-Detection-with-CNNs-and-Optical-Flow\\MAA' \n",
    "#mean_file = 'flow_mean.mat'  # Used as a normalisation for the input of the network\n",
    "\n",
    "save_features = False  # Boolean flag if we save features in h5py\n",
    "save_plots = True\n",
    "load_data = False\n",
    "\n",
    "# Set to 'True' if you want to restore a previous trained models\n",
    "# Training is skipped and test is done\n",
    "use_checkpoint = True # Set to True or False\n",
    "# --------------------------\n",
    "\n",
    "best_model_path = 'models/'\n",
    "plots_folder = 'plots/'\n",
    "\n",
    "features_file = 'features_MAA.h5'\n",
    "labels_file = 'labels_MAA.h5'\n",
    "features_key = 'features'\n",
    "labels_key = 'labels'\n",
    "\n",
    "rgb_file = 'rgb_MAA.h5'\n",
    "rgb_key = 'rgb'\n",
    "\n",
    "# Hyper parameters\n",
    "batch_norm = False\n",
    "gpu_num = 1 \n",
    "num_features = [None, 7, 1, 1, 1024]  # Specific dimension of features for 64-frame clips\n",
    "learning_rate = 0.01\n",
    "mini_batch_size = 1\n",
    "weight_0 = 1 # higher weight of 0 prioritizes learning in class 0\n",
    "epochs = 60\n",
    "dropout_prob=0.36\n",
    "\n",
    "optimizer = 'adam'\n",
    "weights = \"rgb_imagenet_and_kinetics\"\n",
    "name = 'train_nn'\n",
    "\n",
    "# Name of the experiment\n",
    "exp = '_lr{}_batchs{}_batchnorm{}_w0_{}_{}_{}'.format(learning_rate,\n",
    "                                                      mini_batch_size,\n",
    "                                                      batch_norm,\n",
    "                                                      weight_0, \n",
    "                                                      name,\n",
    "                                                      weights)\n",
    "# Input dimensions\n",
    "NUM_FRAMES = 64\n",
    "FRAME_HEIGHT = 224\n",
    "FRAME_WIDTH = 224\n",
    "NUM_RGB_CHANNELS = 3\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions \n",
    "def plot_training_info(case, metrics, save, history):\n",
    "    \"\"\"\n",
    "    Function to create plots for train and validation loss and accuracy\n",
    "    Input:\n",
    "    * case: name for the plot, an 'accuracy.png' or 'loss.png' will be concatenated after the name.\n",
    "    * metrics: list of metrics to store: 'loss' and/or 'accuracy'\n",
    "    * save: boolean to store the plots or only show them.\n",
    "    * history: History object returned by the Keras fit function.\n",
    "    \"\"\"\n",
    "    plt.ioff()\n",
    "    if 'accuracy' in metrics:\n",
    "        fig = plt.figure()\n",
    "        plt.plot(history['acc'])\n",
    "        plt.plot(history['val_acc'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        if save:\n",
    "            plt.savefig(case + 'accuracy.png')\n",
    "            plt.gcf().clear()\n",
    "        else:\n",
    "            plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "    # summarize history for loss\n",
    "    if 'loss' in metrics:\n",
    "        fig = plt.figure()\n",
    "        plt.plot(history['loss'])\n",
    "        plt.plot(history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        # plt.ylim(1e-3, 1e-2)\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        if save:\n",
    "            plt.savefig(case + 'loss.png')\n",
    "            plt.gcf().clear()\n",
    "        else:\n",
    "            plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "def list_data(exp_name):\n",
    "    \"\"\"\n",
    "    Function to list existing data set by filename and label \n",
    "    \"\"\"\n",
    "    vids = {'pass': [], 'fail': []}\n",
    "    global data_folder\n",
    "    data_folder = [os.path.join(data_folder, category) for category in experiments[exp_name]]\n",
    "    for path in data_folder:\n",
    "        for file in os.listdir(path):\n",
    "            if not file.lower().endswith('.npy'):\n",
    "                continue\n",
    "            else:\n",
    "                file_dir = os.path.join(path, file)\n",
    "                ID = file_dir.split('\\\\')[-1].rstrip('.npy')\n",
    "                # Classify\n",
    "                result = ID.split('_')[2][1]\n",
    "                if result == \"P\": vids[\"pass\"].append(ID)\n",
    "                else: vids[\"fail\"].append(ID)\n",
    "    return vids\n",
    "\n",
    "\n",
    "def saveFeatures(feature_extractor,\n",
    "                 features_file,\n",
    "                 labels_file,\n",
    "                 features_key,\n",
    "                 labels_key):\n",
    "    \"\"\"\n",
    "    Function to load the RGB data, do a feed-forward through the feature extractor and store the\n",
    "    output feature vectors in the file 'features_file' and the  labels in 'labels_file'.\n",
    "    Input:\n",
    "    * feature_extractor: model without the top layer, which is the classifer\n",
    "    * features_file: path to the hdf5 file where the extracted features are going to be stored\n",
    "    * labels_file: path to the hdf5 file where the labels of the features are going to be stored\n",
    "    * features_key: name of the key for the hdf5 file to store the features\n",
    "    * labels_key: name of the key for the hdf5 file to store the labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Fill the IDs and classes arrays\n",
    "    classes = list_data(exp_name)\n",
    "    class0, class1 = classes['fail'], classes['pass']\n",
    "    num_samples = len(class0) + len(class1)\n",
    "    num_features[0] = num_samples\n",
    "    \n",
    "    # File to store the extracted features and datasets to store them\n",
    "    # IMPORTANT NOTE: 'w' mode totally erases previous data\n",
    "    # Write files in h5py format\n",
    "    h5features = h5py.File(features_file, 'w')\n",
    "    h5labels = h5py.File(labels_file, 'w')\n",
    "    \n",
    "    # Create data sets\n",
    "    dataset_features = h5features.create_dataset(features_key,\n",
    "                                                 shape=num_features,\n",
    "                                                 dtype='float64')\n",
    "    dataset_labels = h5labels.create_dataset(labels_key,\n",
    "                                             shape=(num_samples, 1),\n",
    "                                             dtype='float64')\n",
    "\n",
    "    # Process class 0 \n",
    "    gen = DataGenerator(class0, np.zeros(len(class0)), 1)\n",
    "    for i in range(len(class0)):\n",
    "                        \n",
    "        rgb_images, rgb_labels = gen.__getitem__(i)\n",
    "        predictions = feature_extractor.predict(rgb_images)\n",
    "\n",
    "        dataset_features[i, :] = predictions\n",
    "        dataset_labels[i, :] = 0\n",
    "                \n",
    "        del rgb_images, rgb_labels\n",
    "        gc.collect()\n",
    "        \n",
    "    # Process class 1\n",
    "    gen = DataGenerator(class1, np.ones(len(class1)), 1)\n",
    "    for i in range(len(class0), num_samples):\n",
    "        \n",
    "        rgb_images, rgb_labels = gen.__getitem__(i)        \n",
    "        prediction = feature_extractor.predict(rgb_images)\n",
    "\n",
    "        dataset_features[i, :] = predictions\n",
    "        dataset_labels[i, :]= 1\n",
    "\n",
    "        del rgb_images, rgb_labels\n",
    "        gc.collect()\n",
    "\n",
    "    h5features.close()\n",
    "    h5labels.close()\n",
    "\n",
    "\n",
    "# Reset Keras Session\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    try:\n",
    "        del model # this is from global space - change this as you need\n",
    "        del x\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # print(gc.collect()) # if it's done something you should see a number being outputted\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.99\n",
    "    config.gpu_options.allow_growth = True\n",
    "    K.set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    # I3D ARCHITECTURE\n",
    "    model = Inception_Inflated3d(\n",
    "        include_top=False ,\n",
    "        weights=weights,\n",
    "        input_shape=(NUM_FRAMES, FRAME_HEIGHT, FRAME_WIDTH, NUM_RGB_CHANNELS),\n",
    "        classes=NUM_CLASSES)\n",
    "\n",
    "    # ==================== CLASSIFIER ========================\n",
    "    # Batch size of 1 does not need normalization\n",
    "    # if batch_norm:\n",
    "      #   x = BatchNormalization(axis=-1, momentum=0.99,\n",
    "        #                       epsilon=0.001)(model.output)\n",
    "        \n",
    "    x = Dropout(dropout_prob)(model.output)\n",
    "\n",
    "    x = conv3d_bn(x, NUM_CLASSES, 1, 1, 1, padding='same', \n",
    "            use_bias=True, use_activation_fn=False, use_bn=False, name='Conv3d_6a_1x1')\n",
    "\n",
    "    num_frames_remaining = int(x.shape[1])\n",
    "    x = Reshape((num_frames_remaining, NUM_CLASSES))(x)\n",
    "\n",
    "    # logits (raw scores for each class)\n",
    "    x = Lambda(lambda x: K.mean(x, axis=1, keepdims=False),\n",
    "               output_shape=lambda s: (s[0], s[2]))(x)\n",
    "\n",
    "    # if not endpoint_logit\n",
    "    x = Activation('softmax', name='prediction')(x)\n",
    "\n",
    "    #compile the model\n",
    "    return Model(input = model.input, output = x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer \n",
    "def main(exp_name):\n",
    "    global exp\n",
    "    exp = exp_name + exp\n",
    "    \n",
    "    do_training = True\n",
    "    compute_metrics = True\n",
    "    threshold = 0.5\n",
    "\n",
    "    if do_training:\n",
    "        # Import data\n",
    "        if load_data:\n",
    "            load_data(rgb_file,\n",
    "                      labels_file,\n",
    "                      rgb_key,\n",
    "                      labels_key)\n",
    "            \n",
    "        # # Import data\n",
    "        # h5rgb = h5py.File(rgb_file, 'r')\n",
    "        # h5labels = h5py.File(labels_file, 'r')\n",
    "        \n",
    "        classes = list_data(exp_name)\n",
    "        class0, class1 = classes['fail'], classes['pass']\n",
    "        X_full = np.asarray((class0 + class1))\n",
    "        X_full = np.expand_dims(X_full, axis=1)\n",
    "        _y_full = np.concatenate(((np.zeros(shape = (len(class0),1))), np.ones(shape = (len(class1),1))))\n",
    "        \n",
    "        # X_full will contain all the feature vectors extracted\n",
    "        # X_full = h5rgb[rgb_key]\n",
    "        # _y_full = np.asarray(h5labels[labels_key])\n",
    "        # print(X_full, _y_full)\n",
    "        \n",
    "        # Indices of 0 and 1 in the data set\n",
    "        zeroes_full = np.asarray(np.where(_y_full == 0)[0])\n",
    "        ones_full = np.asarray(np.where(_y_full == 1)[0])\n",
    "        zeroes_full.sort()\n",
    "        ones_full.sort()\n",
    "\n",
    "        # Traditional Machine Learning methodology\n",
    "        # Method get_n_splits() returns the number of splits\n",
    "        \n",
    "        kf_0 = KFold(n_splits=5, shuffle=True)\n",
    "        kf_0.get_n_splits(X_full[zeroes_full, ...])\n",
    "\n",
    "        kf_1 = KFold(n_splits=5, shuffle=True)\n",
    "        kf_1.get_n_splits(X_full[ones_full, ...])\n",
    "\n",
    "        sensitivities = []\n",
    "        specificities = []\n",
    "        fars = []\n",
    "        mdrs = []\n",
    "        accuracies = []\n",
    "        f1s = []\n",
    "        tps = []\n",
    "        tns = []\n",
    "        fps = []\n",
    "        fns = []\n",
    "\n",
    "        fold_number = 1 \n",
    "        \n",
    "        tprs = []\n",
    "        aucs = []\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "        fig, ax = plt.subplots() # For ROC\n",
    "        \n",
    "        # CROSS-VALIDATION: Stratified partition of the dataset into train/test sets\n",
    "        for ((train_index_0, test_index_0),\n",
    "             (train_index_1, test_index_1)) in zip(\n",
    "            kf_0.split(X_full[zeroes_full, ...]),\n",
    "            kf_1.split(X_full[ones_full, ...])\n",
    "        ):\n",
    "            \n",
    "            train_index_0 = np.asarray(train_index_0)\n",
    "            test_index_0 = np.asarray(test_index_0)\n",
    "            train_index_1 = np.asarray(train_index_1)\n",
    "            test_index_1 = np.asarray(test_index_1)\n",
    "\n",
    "            # Train and Test Set\n",
    "            X = np.concatenate((X_full[zeroes_full, ...][train_index_0, ...],\n",
    "                                X_full[ones_full, ...][train_index_1, ...]))\n",
    "            _y = np.concatenate((_y_full[zeroes_full, ...][train_index_0, ...],\n",
    "                                 _y_full[ones_full, ...][train_index_1, ...]))\n",
    "            X2 = np.concatenate((X_full[zeroes_full, ...][test_index_0, ...],\n",
    "                                 X_full[ones_full, ...][test_index_1, ...]))\n",
    "            _y2 = np.concatenate((_y_full[zeroes_full, ...][test_index_0, ...],\n",
    "                                  _y_full[ones_full, ...][test_index_1, ...]))\n",
    "\n",
    "            # Create a validation subset from the training set\n",
    "            val_size = 0.5\n",
    "            \n",
    "            zeroes = np.asarray(np.where(_y == 0)[0])\n",
    "            ones = np.asarray(np.where(_y == 1)[0])\n",
    "            \n",
    "            zeroes.sort()\n",
    "            ones.sort()\n",
    "\n",
    "            trainval_split_0 = StratifiedShuffleSplit(n_splits=1,\n",
    "                                                      test_size=val_size / 2,\n",
    "                                                      random_state=1)\n",
    "            indices_0 = trainval_split_0.split(X[zeroes, ...],\n",
    "                                               np.argmax(_y[zeroes, ...], 1))\n",
    "            trainval_split_1 = StratifiedShuffleSplit(n_splits=1,\n",
    "                                                      test_size=val_size / 2,\n",
    "                                                      random_state=1)\n",
    "            indices_1 = trainval_split_1.split(X[ones, ...],\n",
    "                                               np.argmax(_y[ones, ...], 1))\n",
    "            \n",
    "            train_indices_0, val_indices_0 = indices_0.__next__()\n",
    "            train_indices_1, val_indices_1 = indices_1.__next__()\n",
    "\n",
    "            X_train = np.concatenate([X[zeroes, ...][train_indices_0, ...],\n",
    "                                      X[ones, ...][train_indices_1, ...]], axis=0)\n",
    "            y_train = np.concatenate([_y[zeroes, ...][train_indices_0, ...],\n",
    "                                      _y[ones, ...][train_indices_1, ...]], axis=0)\n",
    "            X_val = np.concatenate([X[zeroes, ...][val_indices_0, ...],\n",
    "                                    X[ones, ...][val_indices_1, ...]], axis=0)\n",
    "            y_val = np.concatenate([_y[zeroes, ...][val_indices_0, ...],\n",
    "                                    _y[ones, ...][val_indices_1, ...]], axis=0)\n",
    "            \n",
    "            X_train = X_train.flatten()\n",
    "            X_val = X_val.flatten()\n",
    "            y_train = y_train.flatten()\n",
    "            y_val = y_val.flatten()\n",
    "            X2 = X2.flatten()\n",
    "            _y2 = _y2.flatten()\n",
    "            \n",
    "            # Generators\n",
    "            training_generator = DataGenerator(X_train, y_train, mini_batch_size*gpu_num)\n",
    "            validation_generator = DataGenerator(X_val, y_val, mini_batch_size*gpu_num)\n",
    "\n",
    "            reset_keras()\n",
    "    \n",
    "            model = build_model()\n",
    "            adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "            # opt = SGD(lr=learning_rate, momentum=0.0, nesterov=False)\n",
    "            model.compile(adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "            \n",
    "            fold_best_model_path = best_model_path + exp + '_MAA_fold_{}.h5'.format(fold_number)\n",
    "            \n",
    "            if not use_checkpoint:\n",
    "                # ==================== TRAINING ========================\n",
    "                # weighting of each class: only the fall class gets\n",
    "                # a different weight\n",
    "                class_weight = {0: weight_0, 1: 1}\n",
    "\n",
    "                # callback definition\n",
    "                # Choose the monitored metric\n",
    "                metric = 'val_loss'\n",
    "                e = EarlyStopping(monitor=metric, min_delta=0, patience=5,\n",
    "                                  mode='auto', restore_best_weights=True)\n",
    "                c = ModelCheckpoint(fold_best_model_path,\n",
    "                                    monitor=metric,\n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=False, mode='auto')\n",
    "                callbacks = [e, c]\n",
    "\n",
    "                # Batch training\n",
    "                history = model.fit_generator(generator=training_generator,\n",
    "                                         validation_data=validation_generator,\n",
    "                                         steps_per_epoch=len(training_generator),\n",
    "                                         nb_epoch=epochs,\n",
    "                                         class_weight=class_weight,\n",
    "                                         callbacks=callbacks, \n",
    "                                         use_multiprocessing=True,\n",
    "                                         workers=6,\n",
    "                                         shuffle=True)\n",
    "               \n",
    "                plot_training_info(plots_folder + exp + '_fold{}'.format(fold_number), ['accuracy', 'loss'],\n",
    "                                   save_plots, history.history)\n",
    "                \n",
    "            # ==================== EVALUATION ========================\n",
    "            \n",
    "            # Load best model\n",
    "            print('\\nModel loaded from checkpoint')\n",
    "\n",
    "            model = load_model(fold_best_model_path)\n",
    "\n",
    "            test_generator = DataGenerator(X2, _y2, shuffle=False)\n",
    "            \n",
    "            if compute_metrics:\n",
    "                predicted = model.predict_generator(test_generator)\n",
    "                y_score = np.copy(predicted)\n",
    "\n",
    "                predicted = predicted[:,1]\n",
    "\n",
    "                for i in range(len(predicted)):\n",
    "                    if predicted[i] < threshold:\n",
    "                        predicted[i] = 0\n",
    "                    else:\n",
    "                        predicted[i] = 1\n",
    "\n",
    "                # Array of predictions 0/1\n",
    "                predicted = np.asarray(predicted).astype(int)\n",
    "                \n",
    "                # Compute metrics and print them\n",
    "                cm = confusion_matrix(_y2, predicted, labels=[0, 1])\n",
    "                tp = cm[0][0]\n",
    "                fn = cm[0][1]\n",
    "                fp = cm[1][0]\n",
    "                tn = cm[1][1]\n",
    "                \n",
    "                tpr = tp / float(tp + fn)\n",
    "                fpr = fp / float(fp + tn)\n",
    "                fnr = fn / float(fn + tp)\n",
    "                tnr = tn / float(tn + fp)\n",
    "                accuracy = accuracy_score(_y2, predicted)\n",
    "                precision = tp / float(tp + fp)\n",
    "                recall = tp / float(tp + fn)\n",
    "                specificity = tn / float(tn + fp)\n",
    "        \n",
    "                try:\n",
    "                    f1 = 2 * float(precision * recall) / float(precision + recall)                \n",
    "                except:\n",
    "                    f1 = 0\n",
    "                    print(\"An exception occurred\")\n",
    "                \n",
    "                print('\\n')\n",
    "                print('FOLD {} results:'.format(fold_number))\n",
    "                print('TP: {}, TN: {}, FP: {}, FN: {}'.format(tp, tn, fp, fn))\n",
    "                print('TPR: {}, TNR: {}, FPR: {}, FNR: {}'.format(tpr, tnr, fpr, fnr))\n",
    "                print('Sensitivity/Recall: {}'.format(recall))\n",
    "                print('Specificity: {}'.format(specificity))\n",
    "                print('Precision: {}'.format(precision))\n",
    "                print('F1-measure: {}'.format(f1))\n",
    "                print('Accuracy: {}'.format(accuracy))\n",
    "                print('\\n')\n",
    "\n",
    "                # Store the metrics for this epoch\n",
    "                sensitivities.append(tp / float(tp + fn))\n",
    "                specificities.append(tn / float(tn + fp))\n",
    "                fars.append(fpr)\n",
    "                mdrs.append(fnr)\n",
    "                accuracies.append(accuracy)\n",
    "                f1s.append(f1)\n",
    "                \n",
    "                tps.append(tp)\n",
    "                tns.append(tn)\n",
    "                fps.append(fp)\n",
    "                fns.append(fn)\n",
    "                \n",
    "                # Binarize the output\n",
    "                _y2 = label_binarize(_y2, classes=[1, 0])\n",
    "                n_classes = _y2.shape[1] \n",
    "                \n",
    "                fpr = dict()\n",
    "                tpr = dict()\n",
    "                roc_auc = dict()\n",
    "                \n",
    "                for i in range(n_classes):\n",
    "                    fpr[i], tpr[i], _ = roc_curve(_y2[:, i], y_score[:, i])\n",
    "                    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "                lw = 2\n",
    "                color = ['g', 'r', 'c', 'm', 'y']\n",
    "                plt.plot(fpr[0], tpr[0],\n",
    "                         lw=lw, color=color[fold_number - 1],\n",
    "                         label= 'ROC fold {}'.format(fold_number) + ' ' + '(area = %0.2f)' % roc_auc[0])\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "                plt.xlim([0.0, 1.0])\n",
    "                plt.ylim([0.0, 1.05])\n",
    "                plt.xlabel('False Positive Rate', fontfamily= 'Palatino Linotype', fontsize=15)\n",
    "                plt.ylabel('True Positive Rate', fontfamily= 'Palatino Linotype', fontsize=15)\n",
    "                plt.title('Experiment 3 ROC Curves of Class Slips', fontfamily= 'Palatino Linotype', fontsize=15)\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                \n",
    "                font = {'family' : 'Palatino Linotype', 'size':  10}\n",
    "                plt.rc('font', **font)\n",
    "                \n",
    "                # ROC curve plotting\n",
    "                interp_tpr = np.interp(mean_fpr, fpr[0], tpr[0])\n",
    "                interp_tpr[0] = 0.0\n",
    "                tprs.append(interp_tpr)\n",
    "                aucs.append(roc_auc[0])\n",
    "                \n",
    "                fold_number += 1\n",
    "\n",
    "                \n",
    "    print('5-FOLD CROSS-VALIDATION RESULTS ===================')\n",
    "    print(\"Sensitivity: %.2f (+/- %.2f)\" % (np.mean(sensitivities), np.std(sensitivities)))\n",
    "    print(\"Specificity: %.2f (+/- %.2f)\" % (np.mean(specificities), np.std(specificities)))\n",
    "    print(\"FAR: %.2f (+/- %.2f)\" % (np.mean(fars), np.std(fars)))  # False alarm rates \n",
    "    print(\"MDR: %.2f (+/- %.2f)\" % (np.mean(mdrs), np.std(mdrs)))  # Missed detection rates\n",
    "    print(\"Accuracy: %.2f (+/- %.2f)\" % (np.mean(accuracies), np.std(accuracies)))\n",
    "    print(\"F1: %.2f (+/- %.2f)\" % (np.mean(f1s), np.std(f1s)))\n",
    "    \n",
    "    print(\"tp: %.2f (+/- %.2f)\" % (np.mean(tps), np.std(tps)))\n",
    "    print(\"fp: %.2f (+/- %.2f)\" % (np.mean(fps), np.std(fps)))\n",
    "    print(\"tn: %.2f (+/- %.2f)\" % (np.mean(tns), np.std(tns)))\n",
    "    print(\"fn: %.2f (+/- %.2f)\" % (np.mean(fns), np.std(fns)))\n",
    " \n",
    "    # ROC\n",
    "    font = {'family' : 'Palatino Linotype', 'size':  12}\n",
    "    plt.rc('font', **font)\n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "            label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                    label=r'$\\pm$ 1 std. dev.')\n",
    "    \n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    \n",
    "    plt.savefig('ROC for exp3')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "Model loaded from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:185: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "\n",
      "\n",
      "FOLD 1 results:\n",
      "TP: 10, TN: 9, FP: 3, FN: 2\n",
      "TPR: 0.8333333333333334, TNR: 0.75, FPR: 0.25, FNR: 0.16666666666666666\n",
      "Sensitivity/Recall: 0.8333333333333334\n",
      "Specificity: 0.75\n",
      "Precision: 0.7692307692307693\n",
      "F1-measure: 0.8\n",
      "Accuracy: 0.7916666666666666\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:185: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from checkpoint\n",
      "\n",
      "\n",
      "FOLD 2 results:\n",
      "TP: 9, TN: 9, FP: 3, FN: 3\n",
      "TPR: 0.75, TNR: 0.75, FPR: 0.25, FNR: 0.25\n",
      "Sensitivity/Recall: 0.75\n",
      "Specificity: 0.75\n",
      "Precision: 0.75\n",
      "F1-measure: 0.75\n",
      "Accuracy: 0.75\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:185: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from checkpoint\n",
      "\n",
      "\n",
      "FOLD 3 results:\n",
      "TP: 10, TN: 8, FP: 4, FN: 2\n",
      "TPR: 0.8333333333333334, TNR: 0.6666666666666666, FPR: 0.3333333333333333, FNR: 0.16666666666666666\n",
      "Sensitivity/Recall: 0.8333333333333334\n",
      "Specificity: 0.6666666666666666\n",
      "Precision: 0.7142857142857143\n",
      "F1-measure: 0.7692307692307692\n",
      "Accuracy: 0.75\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:185: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from checkpoint\n",
      "\n",
      "\n",
      "FOLD 4 results:\n",
      "TP: 8, TN: 12, FP: 0, FN: 4\n",
      "TPR: 0.6666666666666666, TNR: 1.0, FPR: 0.0, FNR: 0.3333333333333333\n",
      "Sensitivity/Recall: 0.6666666666666666\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "F1-measure: 0.8\n",
      "Accuracy: 0.8333333333333334\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:185: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model loaded from checkpoint\n",
      "\n",
      "\n",
      "FOLD 5 results:\n",
      "TP: 7, TN: 10, FP: 2, FN: 5\n",
      "TPR: 0.5833333333333334, TNR: 0.8333333333333334, FPR: 0.16666666666666666, FNR: 0.4166666666666667\n",
      "Sensitivity/Recall: 0.5833333333333334\n",
      "Specificity: 0.8333333333333334\n",
      "Precision: 0.7777777777777778\n",
      "F1-measure: 0.6666666666666666\n",
      "Accuracy: 0.7083333333333334\n",
      "\n",
      "\n",
      "5-FOLD CROSS-VALIDATION RESULTS ===================\n",
      "Sensitivity: 0.73 (+/- 0.10)\n",
      "Specificity: 0.80 (+/- 0.11)\n",
      "FAR: 0.20 (+/- 0.11)\n",
      "MDR: 0.27 (+/- 0.10)\n",
      "Accuracy: 0.77 (+/- 0.04)\n",
      "F1: 0.76 (+/- 0.05)\n",
      "tp: 8.80 (+/- 1.17)\n",
      "fp: 2.40 (+/- 1.36)\n",
      "tn: 9.60 (+/- 1.36)\n",
      "fn: 3.20 (+/- 1.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:315: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    if not os.path.exists(best_model_path):\n",
    "        os.makedirs(best_model_path)\n",
    "    if not os.path.exists(plots_folder):\n",
    "        os.makedirs(plots_folder)\n",
    "        \n",
    "    # Experiments\n",
    "    # 1. Only with hazardous slips (with more data you gathered) --> 60:60--> same as last time with more data\n",
    "    # 2. Only with normal slips and 'no slips' --> 60:60 --> this can be a fair detection \n",
    "    # 3. Combination of 1+2 --> 120:120\n",
    "    # 4. With small slips --> 60:60\n",
    "    # 5. With all dataset --> 180:180\n",
    "    \n",
    "    experiments = {'exp1':['Hazardous_slips', 'Pass_split1'],\n",
    "                   'exp2':['Normal_slips', 'Pass_split1'],\n",
    "                   'exp3':['Hazardous_slips', 'Normal_slips', 'Pass_split1', 'Pass_split2'],\n",
    "                   'exp4':['Small_slips', 'Pass_split1'],\n",
    "                   'exp5':['Hazardous_slips', 'Normal_slips', 'Pass_split1', 'Pass_split2', 'Small_slips', 'Pass_split3']\n",
    "                  }\n",
    "    \n",
    "    main('exp4') # Make sure you change ROC manually\n",
    "    \n",
    "    # Learning rate\n",
    "    # Memory usage\n",
    "    # Patience\n",
    "    # ROC title and name\n",
    "    # Not use check model\n",
    "    # main function argument\n",
    "    # Change seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-kinetics-i3d",
   "language": "python",
   "name": "keras-kinetics-i3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

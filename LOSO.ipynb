{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "from numpy.random import seed\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from DataGenerator import DataGenerator\n",
    "from i3d_inception import *\n",
    "from utils import *\n",
    "\n",
    "# Helper libraries\n",
    "seed(1)\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.layers import (Input, Conv2D, MaxPooling2D, Flatten, Activation, Dense, Dropout, ZeroPadding2D)\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, auc, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedShuffleSplit\n",
    "from scipy import interp\n",
    "from keras.layers.advanced_activations import ELU\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE VARIABLES ---\n",
    "save_plots = True\n",
    "use_checkpoint = False # Set to True or False\n",
    "\n",
    "# Paths\n",
    "best_model_path = 'test/'\n",
    "plots_folder = 'plots/'\n",
    "\n",
    "# Hyper parameters\n",
    "batch_norm = False\n",
    "gpu_num = 1 \n",
    "learning_rate = 0.01\n",
    "mini_batch_size = 1\n",
    "weight_0 = 1 # higher weight of 0 prioritizes learning in class 0\n",
    "epochs = 60\n",
    "dropout_prob=0.36\n",
    "\n",
    "# Input dimensions\n",
    "NUM_FRAMES = 64\n",
    "FRAME_HEIGHT = 224\n",
    "FRAME_WIDTH = 224\n",
    "NUM_RGB_CHANNELS = 3\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "optimizer = 'adam'\n",
    "weights = \"rgb_imagenet_and_kinetics\"\n",
    "name = 'LOSO'\n",
    "\n",
    "# Name of the experiment\n",
    "exp = '_lr{}_batchs{}_batchnorm{}_w0_{}_{}_{}'.format(learning_rate,\n",
    "                                                      mini_batch_size,\n",
    "                                                      batch_norm,\n",
    "                                                      weight_0, \n",
    "                                                      name,\n",
    "                                                      weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer \n",
    "def main(exp_name, experiments):\n",
    "    global exp\n",
    "    exp = exp_name + exp\n",
    "    \n",
    "    compute_metrics = True\n",
    "    threshold = 0.5\n",
    "\n",
    "    # Import data\n",
    "    classes = list_data(exp_name, experiments)\n",
    "    class0, class1 = classes['fail'], classes['pass']\n",
    "\n",
    "    X_full = np.expand_dims((class0 + class1), axis=1)\n",
    "    _y_full = np.concatenate(((np.zeros(shape = (len(class0),1))), np.ones(shape = (len(class1),1))))\n",
    "    sub_full = np.asarray(extract_subID((class0 + class1)))\n",
    "    \n",
    "    temp = sorted(zip(X_full, _y_full), key=lambda x: x[0][0][12:15])\n",
    "    X_full = np.asarray([item[0] for item in temp])\n",
    "    _y_full = np.asarray([item[1] for item in temp])\n",
    "    sub_full.sort()\n",
    "    sub_full = np.unique(sub_full)\n",
    "\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "    fars = []\n",
    "    mdrs = []\n",
    "    accuracies = []\n",
    "    f1s = []\n",
    "    \n",
    "    tps = []\n",
    "    tns = []\n",
    "    fps = []\n",
    "    fns = []\n",
    "    \n",
    "    tprs = []\n",
    "    aucs = []    \n",
    "    \n",
    "    fold_number = 1 \n",
    "\n",
    "#     mean_fpr = np.linspace(0, 1, 100)\n",
    "#     fig, ax = plt.subplots() # For ROC\n",
    "    \n",
    "    # CROSS-VALIDATION: Stratified partition of the dataset into train/test sets\n",
    "    from sklearn.model_selection import LeaveOneOut, train_test_split\n",
    "    loo = LeaveOneOut()\n",
    "    for train_index, test_index in loo.split(sub_full):\n",
    "        sub_train, sub_test = sub_full[train_index], sub_full[test_index]\n",
    "\n",
    "        # Find the data matching subject ID\n",
    "        X_full, _y_full = X_full.flatten(), _y_full.flatten()\n",
    "        index_train = [False if sub_test[0] in x else True for x in X_full]\n",
    "        index_test = [True if sub_test[0] in x else False for x in X_full]\n",
    "        X_train, y_train = X_full[index_train], _y_full[index_train]\n",
    "        X2, _y2 = X_full[index_test], _y_full[index_test]\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                          test_size=0.1, random_state=42)\n",
    "\n",
    "        # Generators\n",
    "        training_generator = DataGenerator(X_train, y_train, mini_batch_size*gpu_num)\n",
    "        validation_generator = DataGenerator(X_val, y_val, mini_batch_size*gpu_num)\n",
    "\n",
    "        reset_keras()\n",
    "        model = build_model()\n",
    "        adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "        # opt = SGD(lr=learning_rate, momentum=0.0, nesterov=False)\n",
    "        model.compile(adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        fold_best_model_path = best_model_path + exp + '_MAA_fold_{}.h5'.format(fold_number)\n",
    "\n",
    "        if not use_checkpoint:\n",
    "            # ==================== TRAINING ========================\n",
    "            # weighting of each class: only the fall class gets a different weight\n",
    "            class_weight = {0: weight_0, 1: 1}\n",
    "\n",
    "            # callback definition\n",
    "            # Choose the monitored metric\n",
    "            metric = 'val_loss'\n",
    "            e = EarlyStopping(monitor=metric, min_delta=0, patience=8,\n",
    "                              mode='auto', restore_best_weights=True)\n",
    "            c = ModelCheckpoint(fold_best_model_path,\n",
    "                                monitor=metric,\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=False, mode='auto')\n",
    "            callbacks = [e, c]\n",
    "\n",
    "            # Batch training\n",
    "            history = model.fit_generator(generator=training_generator,\n",
    "                                          validation_data=validation_generator,\n",
    "                                          steps_per_epoch=len(training_generator),\n",
    "                                          nb_epoch=epochs,\n",
    "                                          class_weight=class_weight,\n",
    "                                          callbacks=callbacks,\n",
    "                                          use_multiprocessing=True,\n",
    "                                          workers=6,\n",
    "                                          shuffle=True)\n",
    "\n",
    "            plot_training_info(plots_folder + exp + '_fold{}'.format(fold_number), ['accuracy', 'loss'],\n",
    "                               save_plots, history.history)\n",
    "\n",
    "        # ==================== EVALUATION ========================\n",
    "\n",
    "        # Load best model\n",
    "        print('\\nModel loaded from checkpoint')\n",
    "        print(sub_test[0])\n",
    "\n",
    "        model = load_model(fold_best_model_path)\n",
    "        test_generator = DataGenerator(X2, _y2, shuffle=False)\n",
    "        \n",
    "        if compute_metrics:\n",
    "            predicted = model.predict_generator(test_generator)\n",
    "            y_score = np.copy(predicted)\n",
    "\n",
    "            predicted = predicted[:,1]\n",
    "\n",
    "            for i in range(len(predicted)):\n",
    "                if predicted[i] < threshold:\n",
    "                    predicted[i] = 0\n",
    "                else:\n",
    "                    predicted[i] = 1\n",
    "\n",
    "            # Array of predictions 0/1\n",
    "            predicted = np.asarray(predicted).astype(int)\n",
    "\n",
    "            # Compute metrics and print them\n",
    "            cm = confusion_matrix(_y2, predicted, labels=[0, 1])\n",
    "            tp = cm[0][0]\n",
    "            fn = cm[0][1]\n",
    "            fp = cm[1][0]\n",
    "            tn = cm[1][1]\n",
    "\n",
    "            tpr = tp / float(tp + fn)\n",
    "            fpr = fp / float(fp + tn)\n",
    "            fnr = fn / float(fn + tp)\n",
    "            tnr = tn / float(tn + fp)\n",
    "            accuracy = accuracy_score(_y2, predicted)\n",
    "            precision = tp / float(tp + fp)\n",
    "            recall = tp / float(tp + fn)\n",
    "            specificity = tn / float(tn + fp)\n",
    "\n",
    "            try:\n",
    "                f1 = 2 * float(precision * recall) / float(precision + recall)                \n",
    "            except:\n",
    "                f1 = 0\n",
    "                print(\"An exception occurred\")\n",
    "\n",
    "            print('\\n')\n",
    "            print('FOLD {} results:'.format(fold_number))\n",
    "            print('TP: {}, TN: {}, FP: {}, FN: {}'.format(tp, tn, fp, fn))\n",
    "            print('TPR: {}, TNR: {}, FPR: {}, FNR: {}'.format(tpr, tnr, fpr, fnr))\n",
    "            print('Sensitivity/Recall: {}'.format(recall))\n",
    "            print('Specificity: {}'.format(specificity))\n",
    "            print('Precision: {}'.format(precision))\n",
    "            print('F1-measure: {}'.format(f1))\n",
    "            print('Accuracy: {}'.format(accuracy))\n",
    "            print('\\n')\n",
    "\n",
    "            # Store the metrics for this epoch\n",
    "            sensitivities.append(tp / float(tp + fn))\n",
    "            specificities.append(tn / float(tn + fp))\n",
    "            fars.append(fpr)\n",
    "            mdrs.append(fnr)\n",
    "            accuracies.append(accuracy)\n",
    "            f1s.append(f1)\n",
    "\n",
    "            tps.append(tp)\n",
    "            tns.append(tn)\n",
    "            fps.append(fp)\n",
    "            fns.append(fn)\n",
    "\n",
    "#             # Binarize the output\n",
    "#             _y2 = label_binarize(_y2, classes=[1, 0])\n",
    "#             n_classes = _y2.shape[1] \n",
    "\n",
    "#             fpr = dict()\n",
    "#             tpr = dict()\n",
    "#             roc_auc = dict()\n",
    "\n",
    "#             for i in range(n_classes):\n",
    "#                 fpr[i], tpr[i], _ = roc_curve(_y2[:, i], y_score[:, i])\n",
    "#                 roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "#             lw = 2\n",
    "#             color = ['g', 'r', 'c', 'm', 'y']\n",
    "#             plt.plot(fpr[0], tpr[0],\n",
    "#                      lw=lw, color=color[fold_number - 1],\n",
    "#                      label= 'ROC fold {}'.format(fold_number) + ' ' + '(area = %0.2f)' % roc_auc[0])\n",
    "#             plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "#             plt.xlim([0.0, 1.0])\n",
    "#             plt.ylim([0.0, 1.05])\n",
    "#             plt.xlabel('False Positive Rate', fontfamily= 'Palatino Linotype')\n",
    "#             plt.ylabel('True Positive Rate', fontfamily= 'Palatino Linotype')\n",
    "#             plt.title('Experiment 4 ROC Curves of Class Slips', fontfamily= 'Palatino Linotype')\n",
    "#             plt.legend(loc=\"lower right\")\n",
    "\n",
    "# #                 font = {'family' : 'Palatino Linotype', 'size':  10}\n",
    "# #                 plt.rc('font', **font)\n",
    "\n",
    "#             # ROC curve plotting\n",
    "#             interp_tpr = np.interp(mean_fpr, fpr[0], tpr[0])\n",
    "#             interp_tpr[0] = 0.0\n",
    "#             tprs.append(interp_tpr)\n",
    "#             aucs.append(roc_auc[0])\n",
    "\n",
    "        fold_number += 1\n",
    "\n",
    "    print('18-FOLD CROSS-VALIDATION RESULTS ===================')\n",
    "    print(\"Sensitivity: %.2f (+/- %.2f)\" % (np.mean(sensitivities), np.std(sensitivities)))\n",
    "    print(\"Specificity: %.2f (+/- %.2f)\" % (np.mean(specificities), np.std(specificities)))\n",
    "    print(\"FAR: %.2f (+/- %.2f)\" % (np.mean(fars), np.std(fars)))  # False alarm rates \n",
    "    print(\"MDR: %.2f (+/- %.2f)\" % (np.mean(mdrs), np.std(mdrs)))  # Missed detection rates\n",
    "    print(\"Accuracy: %.2f (+/- %.2f)\" % (np.mean(accuracies), np.std(accuracies)))\n",
    "    print(\"F1: %.2f (+/- %.2f)\" % (np.mean(f1s), np.std(f1s)))\n",
    "\n",
    "    print(\"tp: %.2f (+/- %.2f)\" % (np.mean(tps), np.std(tps)))\n",
    "    print(\"fp: %.2f (+/- %.2f)\" % (np.mean(fps), np.std(fps)))\n",
    "    print(\"tn: %.2f (+/- %.2f)\" % (np.mean(tns), np.std(tns)))\n",
    "    print(\"fn: %.2f (+/- %.2f)\" % (np.mean(fns), np.std(fns)))\n",
    "\n",
    "#     # ROC\n",
    "#     font = {'family' : 'Palatino Linotype', 'size':  10}\n",
    "#     plt.rc('font', **font)\n",
    "\n",
    "#     ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "\n",
    "#     mean_tpr = np.mean(tprs, axis=0)\n",
    "#     mean_tpr[-1] = 1.0\n",
    "#     mean_auc = auc(mean_fpr, mean_tpr)\n",
    "#     std_auc = np.std(aucs)\n",
    "#     ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "#             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "#             lw=2, alpha=.8)\n",
    "\n",
    "#     std_tpr = np.std(tprs, axis=0)\n",
    "#     tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "#     tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "#     ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "#                     label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "#     ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],)\n",
    "#     ax.legend(loc=\"lower right\")\n",
    "\n",
    "#     plt.show()\n",
    "#     plt.savefig('ROC for exp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=316, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/60\n",
      "316/316 [==============================] - 302s 957ms/step - loss: 0.6405 - acc: 0.6361 - val_loss: 5.7738 - val_acc: 0.5556\n",
      "Epoch 2/60\n",
      "316/316 [==============================] - 285s 901ms/step - loss: 0.4555 - acc: 0.8133 - val_loss: 0.3166 - val_acc: 0.8611\n",
      "Epoch 3/60\n",
      "316/316 [==============================] - 296s 936ms/step - loss: 0.4061 - acc: 0.8481 - val_loss: 0.9095 - val_acc: 0.6944\n",
      "Epoch 4/60\n",
      "316/316 [==============================] - 271s 856ms/step - loss: 0.4085 - acc: 0.8228 - val_loss: 0.5199 - val_acc: 0.7222\n",
      "Epoch 5/60\n",
      "316/316 [==============================] - 266s 843ms/step - loss: 0.3751 - acc: 0.8544 - val_loss: 0.4589 - val_acc: 0.8056\n",
      "Epoch 6/60\n",
      "316/316 [==============================] - 281s 888ms/step - loss: 0.3741 - acc: 0.8639 - val_loss: 0.3854 - val_acc: 0.9167\n",
      "Epoch 7/60\n",
      "316/316 [==============================] - 303s 960ms/step - loss: 0.3031 - acc: 0.8797 - val_loss: 0.4710 - val_acc: 0.8333\n",
      "Epoch 8/60\n",
      "316/316 [==============================] - 278s 880ms/step - loss: 0.2624 - acc: 0.8987 - val_loss: 1.2480 - val_acc: 0.8056\n",
      "Epoch 9/60\n",
      "316/316 [==============================] - 282s 894ms/step - loss: 0.2395 - acc: 0.9177 - val_loss: 0.7868 - val_acc: 0.8611\n",
      "Epoch 10/60\n",
      "316/316 [==============================] - 270s 855ms/step - loss: 0.2269 - acc: 0.9272 - val_loss: 1.4301 - val_acc: 0.8611\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub207\n",
      "\n",
      "\n",
      "FOLD 1 results:\n",
      "TP: 5, TN: 3, FP: 0, FN: 0\n",
      "TPR: 1.0, TNR: 1.0, FPR: 0.0, FNR: 0.0\n",
      "Sensitivity/Recall: 1.0\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "F1-measure: 1.0\n",
      "Accuracy: 1.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=310, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "310/310 [==============================] - 299s 966ms/step - loss: 0.5976 - acc: 0.7290 - val_loss: 0.4495 - val_acc: 0.8000\n",
      "Epoch 2/60\n",
      "310/310 [==============================] - 259s 834ms/step - loss: 0.5012 - acc: 0.7452 - val_loss: 1.1020 - val_acc: 0.4000\n",
      "Epoch 3/60\n",
      "310/310 [==============================] - 281s 905ms/step - loss: 0.4273 - acc: 0.8226 - val_loss: 0.2986 - val_acc: 0.8857\n",
      "Epoch 4/60\n",
      "310/310 [==============================] - 272s 879ms/step - loss: 0.3778 - acc: 0.8484 - val_loss: 0.3245 - val_acc: 0.8571\n",
      "Epoch 5/60\n",
      "310/310 [==============================] - 282s 909ms/step - loss: 0.3669 - acc: 0.8774 - val_loss: 0.6975 - val_acc: 0.6000\n",
      "Epoch 6/60\n",
      "310/310 [==============================] - 270s 870ms/step - loss: 0.4122 - acc: 0.8355 - val_loss: 0.7570 - val_acc: 0.6286\n",
      "Epoch 7/60\n",
      "310/310 [==============================] - 265s 854ms/step - loss: 0.3174 - acc: 0.8871 - val_loss: 0.2604 - val_acc: 0.8571\n",
      "Epoch 8/60\n",
      "310/310 [==============================] - 267s 860ms/step - loss: 0.2809 - acc: 0.9097 - val_loss: 0.4779 - val_acc: 0.8571\n",
      "Epoch 9/60\n",
      "310/310 [==============================] - 269s 868ms/step - loss: 0.2543 - acc: 0.9226 - val_loss: 0.4540 - val_acc: 0.7714\n",
      "Epoch 10/60\n",
      "310/310 [==============================] - 264s 853ms/step - loss: 0.1917 - acc: 0.9226 - val_loss: 0.3763 - val_acc: 0.8286\n",
      "Epoch 11/60\n",
      "310/310 [==============================] - 274s 883ms/step - loss: 0.2082 - acc: 0.9226 - val_loss: 0.5128 - val_acc: 0.9143\n",
      "Epoch 12/60\n",
      "310/310 [==============================] - 260s 839ms/step - loss: 0.1610 - acc: 0.9387 - val_loss: 0.4858 - val_acc: 0.8000\n",
      "Epoch 13/60\n",
      "310/310 [==============================] - 270s 870ms/step - loss: 0.0807 - acc: 0.9806 - val_loss: 0.3659 - val_acc: 0.8857\n",
      "Epoch 14/60\n",
      "310/310 [==============================] - 270s 872ms/step - loss: 0.1012 - acc: 0.9742 - val_loss: 0.8545 - val_acc: 0.7143\n",
      "Epoch 15/60\n",
      "310/310 [==============================] - 264s 852ms/step - loss: 0.1480 - acc: 0.9516 - val_loss: 0.3408 - val_acc: 0.8571\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub228\n",
      "\n",
      "\n",
      "FOLD 2 results:\n",
      "TP: 1, TN: 6, FP: 0, FN: 8\n",
      "TPR: 0.1111111111111111, TNR: 1.0, FPR: 0.0, FNR: 0.8888888888888888\n",
      "Sensitivity/Recall: 0.1111111111111111\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "F1-measure: 0.19999999999999998\n",
      "Accuracy: 0.4666666666666667\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=315, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "315/315 [==============================] - 286s 909ms/step - loss: 0.5098 - acc: 0.7651 - val_loss: 0.7827 - val_acc: 0.7778\n",
      "Epoch 2/60\n",
      "315/315 [==============================] - 253s 804ms/step - loss: 0.6427 - acc: 0.6635 - val_loss: 0.4675 - val_acc: 0.7222\n",
      "Epoch 3/60\n",
      "315/315 [==============================] - 269s 853ms/step - loss: 0.4174 - acc: 0.8381 - val_loss: 0.6838 - val_acc: 0.6111\n",
      "Epoch 4/60\n",
      "315/315 [==============================] - 276s 877ms/step - loss: 0.4079 - acc: 0.8413 - val_loss: 0.6381 - val_acc: 0.6667\n",
      "Epoch 5/60\n",
      "315/315 [==============================] - 270s 859ms/step - loss: 0.3300 - acc: 0.8825 - val_loss: 0.4255 - val_acc: 0.7778\n",
      "Epoch 6/60\n",
      "315/315 [==============================] - 269s 854ms/step - loss: 0.2995 - acc: 0.9016 - val_loss: 0.4431 - val_acc: 0.7778\n",
      "Epoch 7/60\n",
      "315/315 [==============================] - 277s 880ms/step - loss: 0.3004 - acc: 0.8857 - val_loss: 0.3561 - val_acc: 0.9167\n",
      "Epoch 8/60\n",
      "315/315 [==============================] - 269s 853ms/step - loss: 0.2767 - acc: 0.9048 - val_loss: 0.4263 - val_acc: 0.8611\n",
      "Epoch 9/60\n",
      "315/315 [==============================] - 274s 871ms/step - loss: 0.2515 - acc: 0.8952 - val_loss: 0.3095 - val_acc: 0.8611\n",
      "Epoch 10/60\n",
      "315/315 [==============================] - 265s 841ms/step - loss: 0.2386 - acc: 0.9111 - val_loss: 0.5150 - val_acc: 0.7778\n",
      "Epoch 11/60\n",
      "315/315 [==============================] - 275s 874ms/step - loss: 0.2995 - acc: 0.8730 - val_loss: 1.1363 - val_acc: 0.5000\n",
      "Epoch 12/60\n",
      "315/315 [==============================] - 268s 851ms/step - loss: 0.2209 - acc: 0.9333 - val_loss: 0.3793 - val_acc: 0.8056\n",
      "Epoch 13/60\n",
      "315/315 [==============================] - 271s 860ms/step - loss: 0.2015 - acc: 0.9206 - val_loss: 0.3430 - val_acc: 0.8889\n",
      "Epoch 14/60\n",
      "315/315 [==============================] - 273s 865ms/step - loss: 0.1806 - acc: 0.9429 - val_loss: 0.2992 - val_acc: 0.8611\n",
      "Epoch 15/60\n",
      "315/315 [==============================] - 272s 862ms/step - loss: 0.1506 - acc: 0.9397 - val_loss: 0.3371 - val_acc: 0.8333\n",
      "Epoch 16/60\n",
      "315/315 [==============================] - 275s 872ms/step - loss: 0.1460 - acc: 0.9524 - val_loss: 0.3397 - val_acc: 0.8333\n",
      "Epoch 17/60\n",
      "315/315 [==============================] - 269s 855ms/step - loss: 0.1108 - acc: 0.9556 - val_loss: 0.3791 - val_acc: 0.8333\n",
      "Epoch 18/60\n",
      "315/315 [==============================] - 269s 854ms/step - loss: 0.1062 - acc: 0.9683 - val_loss: 0.1812 - val_acc: 0.9444\n",
      "Epoch 19/60\n",
      "315/315 [==============================] - 271s 860ms/step - loss: 0.1403 - acc: 0.9492 - val_loss: 0.3269 - val_acc: 0.8611\n",
      "Epoch 20/60\n",
      "315/315 [==============================] - 273s 868ms/step - loss: 0.1168 - acc: 0.9587 - val_loss: 0.3400 - val_acc: 0.8889\n",
      "Epoch 21/60\n",
      "315/315 [==============================] - 270s 858ms/step - loss: 0.0434 - acc: 0.9810 - val_loss: 0.3402 - val_acc: 0.8889\n",
      "Epoch 22/60\n",
      "315/315 [==============================] - 269s 855ms/step - loss: 0.1693 - acc: 0.9333 - val_loss: 0.4839 - val_acc: 0.8611\n",
      "Epoch 23/60\n",
      "315/315 [==============================] - 284s 900ms/step - loss: 0.1012 - acc: 0.9714 - val_loss: 0.4303 - val_acc: 0.8056\n",
      "Epoch 24/60\n",
      "315/315 [==============================] - 266s 846ms/step - loss: 0.0453 - acc: 0.9905 - val_loss: 0.2963 - val_acc: 0.8611\n",
      "Epoch 25/60\n",
      "315/315 [==============================] - 269s 853ms/step - loss: 0.0072 - acc: 0.9968 - val_loss: 0.2821 - val_acc: 0.8333\n",
      "Epoch 26/60\n",
      "315/315 [==============================] - 271s 861ms/step - loss: 0.0646 - acc: 0.9778 - val_loss: 0.3570 - val_acc: 0.8889\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub232\n",
      "\n",
      "\n",
      "FOLD 3 results:\n",
      "TP: 6, TN: 2, FP: 0, FN: 1\n",
      "TPR: 0.8571428571428571, TNR: 1.0, FPR: 0.0, FNR: 0.14285714285714285\n",
      "Sensitivity/Recall: 0.8571428571428571\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "F1-measure: 0.923076923076923\n",
      "Accuracy: 0.8888888888888888\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=317, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "317/317 [==============================] - 289s 912ms/step - loss: 0.5839 - acc: 0.7035 - val_loss: 1.4840 - val_acc: 0.7778\n",
      "Epoch 2/60\n",
      "317/317 [==============================] - 254s 800ms/step - loss: 0.4555 - acc: 0.8139 - val_loss: 0.4492 - val_acc: 0.6944\n",
      "Epoch 3/60\n",
      "317/317 [==============================] - 275s 866ms/step - loss: 0.3760 - acc: 0.8454 - val_loss: 0.3817 - val_acc: 0.7778\n",
      "Epoch 4/60\n",
      "317/317 [==============================] - 270s 853ms/step - loss: 0.3868 - acc: 0.8360 - val_loss: 0.2885 - val_acc: 0.8889\n",
      "Epoch 5/60\n",
      "317/317 [==============================] - 275s 868ms/step - loss: 0.3288 - acc: 0.8770 - val_loss: 0.3298 - val_acc: 0.8333\n",
      "Epoch 6/60\n",
      "317/317 [==============================] - 271s 855ms/step - loss: 0.3094 - acc: 0.8927 - val_loss: 0.8289 - val_acc: 0.7500\n",
      "Epoch 7/60\n",
      "317/317 [==============================] - 268s 845ms/step - loss: 0.3176 - acc: 0.8864 - val_loss: 0.3480 - val_acc: 0.8056\n",
      "Epoch 8/60\n",
      "317/317 [==============================] - 278s 876ms/step - loss: 0.2831 - acc: 0.9022 - val_loss: 0.4597 - val_acc: 0.8056\n",
      "Epoch 9/60\n",
      "317/317 [==============================] - 270s 851ms/step - loss: 0.2607 - acc: 0.9180 - val_loss: 0.5092 - val_acc: 0.8056\n",
      "Epoch 10/60\n",
      "317/317 [==============================] - 274s 863ms/step - loss: 0.2422 - acc: 0.9211 - val_loss: 0.3678 - val_acc: 0.8333\n",
      "Epoch 11/60\n",
      "317/317 [==============================] - 273s 863ms/step - loss: 0.2020 - acc: 0.9306 - val_loss: 0.6520 - val_acc: 0.6667\n",
      "Epoch 12/60\n",
      "317/317 [==============================] - 272s 860ms/step - loss: 0.1932 - acc: 0.9369 - val_loss: 0.2812 - val_acc: 0.8333\n",
      "Epoch 13/60\n",
      "317/317 [==============================] - 276s 871ms/step - loss: 0.1383 - acc: 0.9590 - val_loss: 0.3500 - val_acc: 0.8056\n",
      "Epoch 14/60\n",
      "317/317 [==============================] - 267s 843ms/step - loss: 0.2458 - acc: 0.9022 - val_loss: 0.7589 - val_acc: 0.6667\n",
      "Epoch 15/60\n",
      "317/317 [==============================] - 273s 861ms/step - loss: 0.1408 - acc: 0.9495 - val_loss: 0.3832 - val_acc: 0.8333\n",
      "Epoch 16/60\n",
      "317/317 [==============================] - 271s 854ms/step - loss: 0.2037 - acc: 0.9306 - val_loss: 0.4147 - val_acc: 0.7500\n",
      "Epoch 17/60\n",
      "317/317 [==============================] - 278s 878ms/step - loss: 0.0907 - acc: 0.9779 - val_loss: 0.6325 - val_acc: 0.7778\n",
      "Epoch 18/60\n",
      "317/317 [==============================] - 270s 853ms/step - loss: 0.0545 - acc: 0.9842 - val_loss: 0.7294 - val_acc: 0.6389\n",
      "Epoch 19/60\n",
      "317/317 [==============================] - 273s 862ms/step - loss: 0.1170 - acc: 0.9685 - val_loss: 0.3686 - val_acc: 0.8333\n",
      "Epoch 20/60\n",
      "317/317 [==============================] - 276s 871ms/step - loss: 0.1118 - acc: 0.9685 - val_loss: 0.2851 - val_acc: 0.8333\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:130: RuntimeWarning: invalid value encountered in true_divide\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:136: RuntimeWarning: invalid value encountered in true_divide\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:157: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "FOLD 4 results:\n",
      "TP: 0, TN: 6, FP: 1, FN: 0\n",
      "TPR: nan, TNR: 0.8571428571428571, FPR: 0.14285714285714285, FNR: nan\n",
      "Sensitivity/Recall: nan\n",
      "Specificity: 0.8571428571428571\n",
      "Precision: 0.0\n",
      "F1-measure: nan\n",
      "Accuracy: 0.8571428571428571\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=316, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "316/316 [==============================] - 291s 921ms/step - loss: 0.6945 - acc: 0.6171 - val_loss: 0.4756 - val_acc: 0.8056\n",
      "Epoch 2/60\n",
      "316/316 [==============================] - 253s 802ms/step - loss: 0.4663 - acc: 0.8006 - val_loss: 0.2990 - val_acc: 0.8889\n",
      "Epoch 3/60\n",
      "316/316 [==============================] - 272s 861ms/step - loss: 0.4095 - acc: 0.8386 - val_loss: 0.3204 - val_acc: 0.8333\n",
      "Epoch 4/60\n",
      "316/316 [==============================] - 278s 880ms/step - loss: 0.3999 - acc: 0.8513 - val_loss: 0.3240 - val_acc: 0.8889\n",
      "Epoch 5/60\n",
      "316/316 [==============================] - 273s 863ms/step - loss: 0.3320 - acc: 0.8481 - val_loss: 0.3556 - val_acc: 0.8611\n",
      "Epoch 6/60\n",
      "316/316 [==============================] - 271s 859ms/step - loss: 0.3462 - acc: 0.8449 - val_loss: 0.2994 - val_acc: 0.8889\n",
      "Epoch 7/60\n",
      "316/316 [==============================] - 269s 851ms/step - loss: 0.3535 - acc: 0.8703 - val_loss: 0.5149 - val_acc: 0.8056\n",
      "Epoch 8/60\n",
      "316/316 [==============================] - 276s 874ms/step - loss: 0.3535 - acc: 0.8513 - val_loss: 0.3773 - val_acc: 0.8611\n",
      "Epoch 9/60\n",
      "316/316 [==============================] - 276s 874ms/step - loss: 0.3424 - acc: 0.8703 - val_loss: 0.3731 - val_acc: 0.8611\n",
      "Epoch 10/60\n",
      "316/316 [==============================] - 266s 841ms/step - loss: 0.2938 - acc: 0.8892 - val_loss: 0.3967 - val_acc: 0.8611\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub243\n",
      "\n",
      "\n",
      "FOLD 5 results:\n",
      "TP: 2, TN: 5, FP: 0, FN: 1\n",
      "TPR: 0.6666666666666666, TNR: 1.0, FPR: 0.0, FNR: 0.3333333333333333\n",
      "Sensitivity/Recall: 0.6666666666666666\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "F1-measure: 0.8\n",
      "Accuracy: 0.875\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=290, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "290/290 [==============================] - 273s 943ms/step - loss: 0.6741 - acc: 0.6448 - val_loss: 0.8347 - val_acc: 0.5455\n",
      "Epoch 2/60\n",
      "290/290 [==============================] - 234s 808ms/step - loss: 0.3519 - acc: 0.8828 - val_loss: 0.6597 - val_acc: 0.7879\n",
      "Epoch 3/60\n",
      "290/290 [==============================] - 250s 864ms/step - loss: 0.6049 - acc: 0.6414 - val_loss: 0.5958 - val_acc: 0.8182\n",
      "Epoch 4/60\n",
      "290/290 [==============================] - 246s 848ms/step - loss: 0.4389 - acc: 0.8034 - val_loss: 0.8562 - val_acc: 0.7879\n",
      "Epoch 5/60\n",
      "290/290 [==============================] - 248s 853ms/step - loss: 0.3906 - acc: 0.8207 - val_loss: 0.5087 - val_acc: 0.8182\n",
      "Epoch 6/60\n",
      "290/290 [==============================] - 250s 862ms/step - loss: 0.3866 - acc: 0.8379 - val_loss: 0.9947 - val_acc: 0.8182\n",
      "Epoch 7/60\n",
      "290/290 [==============================] - 245s 846ms/step - loss: 0.3345 - acc: 0.8724 - val_loss: 0.7731 - val_acc: 0.8485\n",
      "Epoch 8/60\n",
      "290/290 [==============================] - 248s 857ms/step - loss: 0.3018 - acc: 0.8897 - val_loss: 0.7005 - val_acc: 0.8485\n",
      "Epoch 9/60\n",
      "290/290 [==============================] - 245s 846ms/step - loss: 0.2692 - acc: 0.9069 - val_loss: 0.7039 - val_acc: 0.8485\n",
      "Epoch 10/60\n",
      "290/290 [==============================] - 247s 852ms/step - loss: 0.3142 - acc: 0.8862 - val_loss: 1.8194 - val_acc: 0.6061\n",
      "Epoch 11/60\n",
      "290/290 [==============================] - 270s 933ms/step - loss: 0.2516 - acc: 0.9000 - val_loss: 0.4744 - val_acc: 0.8485\n",
      "Epoch 12/60\n",
      "290/290 [==============================] - 256s 884ms/step - loss: 0.1908 - acc: 0.9241 - val_loss: 0.7379 - val_acc: 0.8788\n",
      "Epoch 13/60\n",
      "290/290 [==============================] - 264s 912ms/step - loss: 0.1563 - acc: 0.9448 - val_loss: 0.7982 - val_acc: 0.8485\n",
      "Epoch 14/60\n",
      "290/290 [==============================] - 265s 915ms/step - loss: 0.1800 - acc: 0.9414 - val_loss: 0.5302 - val_acc: 0.7879\n",
      "Epoch 15/60\n",
      "290/290 [==============================] - 263s 907ms/step - loss: 0.1449 - acc: 0.9517 - val_loss: 1.0373 - val_acc: 0.8788\n",
      "Epoch 16/60\n",
      "290/290 [==============================] - 251s 865ms/step - loss: 0.1902 - acc: 0.9345 - val_loss: 0.6166 - val_acc: 0.8485\n",
      "Epoch 17/60\n",
      "290/290 [==============================] - 253s 873ms/step - loss: 0.1268 - acc: 0.9621 - val_loss: 0.4940 - val_acc: 0.8182\n",
      "Epoch 18/60\n",
      "290/290 [==============================] - 248s 854ms/step - loss: 0.1219 - acc: 0.9517 - val_loss: 0.7143 - val_acc: 0.8182\n",
      "Epoch 19/60\n",
      "290/290 [==============================] - 242s 834ms/step - loss: 0.1296 - acc: 0.9517 - val_loss: 0.6710 - val_acc: 0.9091\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub244\n",
      "\n",
      "\n",
      "FOLD 6 results:\n",
      "TP: 15, TN: 12, FP: 0, FN: 10\n",
      "TPR: 0.6, TNR: 1.0, FPR: 0.0, FNR: 0.4\n",
      "Sensitivity/Recall: 0.6\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "F1-measure: 0.7499999999999999\n",
      "Accuracy: 0.7297297297297297\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=307, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "307/307 [==============================] - 275s 897ms/step - loss: 0.6241 - acc: 0.6743 - val_loss: 0.6136 - val_acc: 0.8000\n",
      "Epoch 2/60\n",
      "307/307 [==============================] - 247s 803ms/step - loss: 0.5055 - acc: 0.7818 - val_loss: 0.5386 - val_acc: 0.6857\n",
      "Epoch 3/60\n",
      "307/307 [==============================] - 266s 866ms/step - loss: 0.4629 - acc: 0.8143 - val_loss: 0.4795 - val_acc: 0.7429\n",
      "Epoch 4/60\n",
      "307/307 [==============================] - 265s 864ms/step - loss: 0.3810 - acc: 0.8534 - val_loss: 0.6280 - val_acc: 0.6571\n",
      "Epoch 5/60\n",
      "307/307 [==============================] - 271s 882ms/step - loss: 0.3549 - acc: 0.8632 - val_loss: 0.3839 - val_acc: 0.8286\n",
      "Epoch 6/60\n",
      "307/307 [==============================] - 264s 860ms/step - loss: 0.2920 - acc: 0.8925 - val_loss: 0.3646 - val_acc: 0.8286\n",
      "Epoch 7/60\n",
      "307/307 [==============================] - 262s 853ms/step - loss: 0.2725 - acc: 0.9121 - val_loss: 0.3529 - val_acc: 0.8286\n",
      "Epoch 8/60\n",
      "307/307 [==============================] - 269s 878ms/step - loss: 0.2466 - acc: 0.9218 - val_loss: 0.4605 - val_acc: 0.8571\n",
      "Epoch 9/60\n",
      "307/307 [==============================] - 263s 857ms/step - loss: 0.2444 - acc: 0.9153 - val_loss: 0.4468 - val_acc: 0.8571\n",
      "Epoch 10/60\n",
      "307/307 [==============================] - 271s 883ms/step - loss: 0.2927 - acc: 0.9023 - val_loss: 0.3300 - val_acc: 0.8571\n",
      "Epoch 11/60\n",
      "307/307 [==============================] - 270s 878ms/step - loss: 0.1903 - acc: 0.9349 - val_loss: 1.4559 - val_acc: 0.8000\n",
      "Epoch 12/60\n",
      "307/307 [==============================] - 271s 883ms/step - loss: 0.1743 - acc: 0.9511 - val_loss: 0.4483 - val_acc: 0.8571\n",
      "Epoch 13/60\n",
      "307/307 [==============================] - 275s 897ms/step - loss: 0.1868 - acc: 0.9479 - val_loss: 0.3443 - val_acc: 0.8571\n",
      "Epoch 14/60\n",
      "307/307 [==============================] - 269s 876ms/step - loss: 0.1520 - acc: 0.9577 - val_loss: 0.3489 - val_acc: 0.8571\n",
      "Epoch 15/60\n",
      "307/307 [==============================] - 271s 883ms/step - loss: 0.2139 - acc: 0.9316 - val_loss: 0.5011 - val_acc: 0.8571\n",
      "Epoch 16/60\n",
      "307/307 [==============================] - 277s 903ms/step - loss: 0.1049 - acc: 0.9739 - val_loss: 0.7256 - val_acc: 0.8571\n",
      "Epoch 17/60\n",
      "307/307 [==============================] - 275s 897ms/step - loss: 0.1407 - acc: 0.9446 - val_loss: 0.4589 - val_acc: 0.7714\n",
      "Epoch 18/60\n",
      "307/307 [==============================] - 264s 860ms/step - loss: 0.1401 - acc: 0.9609 - val_loss: 0.6480 - val_acc: 0.8286\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:130: RuntimeWarning: invalid value encountered in true_divide\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:135: RuntimeWarning: invalid value encountered in true_divide\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:136: RuntimeWarning: invalid value encountered in true_divide\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:157: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "FOLD 7 results:\n",
      "TP: 0, TN: 18, FP: 0, FN: 0\n",
      "TPR: nan, TNR: 1.0, FPR: 0.0, FNR: nan\n",
      "Sensitivity/Recall: nan\n",
      "Specificity: 1.0\n",
      "Precision: nan\n",
      "F1-measure: nan\n",
      "Accuracy: 1.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=315, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "315/315 [==============================] - 283s 898ms/step - loss: 0.6303 - acc: 0.6603 - val_loss: 2.2037 - val_acc: 0.5556\n",
      "Epoch 2/60\n",
      "315/315 [==============================] - 254s 806ms/step - loss: 0.4356 - acc: 0.8127 - val_loss: 0.3441 - val_acc: 0.8333\n",
      "Epoch 3/60\n",
      "315/315 [==============================] - 275s 874ms/step - loss: 0.3993 - acc: 0.8190 - val_loss: 0.5951 - val_acc: 0.6389\n",
      "Epoch 4/60\n",
      "315/315 [==============================] - 274s 869ms/step - loss: 0.4005 - acc: 0.8444 - val_loss: 0.4418 - val_acc: 0.8333\n",
      "Epoch 5/60\n",
      "315/315 [==============================] - 280s 890ms/step - loss: 0.3907 - acc: 0.8635 - val_loss: 0.7821 - val_acc: 0.4444\n",
      "Epoch 6/60\n",
      "315/315 [==============================] - 289s 917ms/step - loss: 0.3321 - acc: 0.8603 - val_loss: 0.5304 - val_acc: 0.7222\n",
      "Epoch 7/60\n",
      "315/315 [==============================] - 286s 908ms/step - loss: 0.3213 - acc: 0.8889 - val_loss: 0.4312 - val_acc: 0.7778\n",
      "Epoch 8/60\n",
      "315/315 [==============================] - 2448s 8s/step - loss: 0.3056 - acc: 0.8794 - val_loss: 0.3907 - val_acc: 0.8056\n",
      "Epoch 9/60\n",
      "315/315 [==============================] - 327s 1s/step - loss: 0.2753 - acc: 0.8889 - val_loss: 0.4936 - val_acc: 0.7778\n",
      "Epoch 10/60\n",
      "315/315 [==============================] - 387s 1s/step - loss: 0.2770 - acc: 0.8889 - val_loss: 0.4073 - val_acc: 0.8056\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub247\n",
      "\n",
      "\n",
      "FOLD 8 results:\n",
      "TP: 1, TN: 8, FP: 0, FN: 0\n",
      "TPR: 1.0, TNR: 1.0, FPR: 0.0, FNR: 0.0\n",
      "Sensitivity/Recall: 1.0\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "F1-measure: 1.0\n",
      "Accuracy: 1.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=295, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "295/295 [==============================] - 379s 1s/step - loss: 0.5961 - acc: 0.6881 - val_loss: 6.2054 - val_acc: 0.4848\n",
      "Epoch 2/60\n",
      "295/295 [==============================] - 288s 978ms/step - loss: 0.5368 - acc: 0.7254 - val_loss: 0.4800 - val_acc: 0.7879\n",
      "Epoch 3/60\n",
      "295/295 [==============================] - 386s 1s/step - loss: 0.5263 - acc: 0.7559 - val_loss: 0.4188 - val_acc: 0.9697\n",
      "Epoch 4/60\n",
      "295/295 [==============================] - 385s 1s/step - loss: 0.3687 - acc: 0.8441 - val_loss: 0.5486 - val_acc: 0.7273\n",
      "Epoch 5/60\n",
      "295/295 [==============================] - 379s 1s/step - loss: 0.3660 - acc: 0.8678 - val_loss: 0.3269 - val_acc: 0.9091\n",
      "Epoch 6/60\n",
      "295/295 [==============================] - 387s 1s/step - loss: 0.3747 - acc: 0.8542 - val_loss: 0.4874 - val_acc: 0.5455\n",
      "Epoch 7/60\n",
      "295/295 [==============================] - 372s 1s/step - loss: 0.3922 - acc: 0.8305 - val_loss: 1.4020 - val_acc: 0.5455\n",
      "Epoch 8/60\n",
      "295/295 [==============================] - 382s 1s/step - loss: 0.3770 - acc: 0.8407 - val_loss: 0.5962 - val_acc: 0.6667\n",
      "Epoch 9/60\n",
      "295/295 [==============================] - 377s 1s/step - loss: 0.2792 - acc: 0.8949 - val_loss: 0.4037 - val_acc: 0.8788\n",
      "Epoch 10/60\n",
      "295/295 [==============================] - 389s 1s/step - loss: 0.2486 - acc: 0.8983 - val_loss: 0.6137 - val_acc: 0.7273\n",
      "Epoch 11/60\n",
      "295/295 [==============================] - 380s 1s/step - loss: 0.3232 - acc: 0.8949 - val_loss: 0.2015 - val_acc: 0.9697\n",
      "Epoch 12/60\n",
      "295/295 [==============================] - 385s 1s/step - loss: 0.2258 - acc: 0.9186 - val_loss: 0.1994 - val_acc: 0.9394\n",
      "Epoch 13/60\n",
      "295/295 [==============================] - 366s 1s/step - loss: 0.2703 - acc: 0.8983 - val_loss: 2.1926 - val_acc: 0.5455\n",
      "Epoch 14/60\n",
      "295/295 [==============================] - 400s 1s/step - loss: 0.2813 - acc: 0.8881 - val_loss: 1.5904 - val_acc: 0.7273\n",
      "Epoch 15/60\n",
      "295/295 [==============================] - 383s 1s/step - loss: 0.2693 - acc: 0.9051 - val_loss: 0.3860 - val_acc: 0.8182\n",
      "Epoch 16/60\n",
      "295/295 [==============================] - 389s 1s/step - loss: 0.2241 - acc: 0.9322 - val_loss: 1.9470 - val_acc: 0.6970\n",
      "Epoch 17/60\n",
      "295/295 [==============================] - 391s 1s/step - loss: 0.2501 - acc: 0.9186 - val_loss: 0.3632 - val_acc: 0.8788\n",
      "Epoch 18/60\n",
      "295/295 [==============================] - 406s 1s/step - loss: 0.2035 - acc: 0.9288 - val_loss: 1.8462 - val_acc: 0.7576\n",
      "Epoch 19/60\n",
      "295/295 [==============================] - 410s 1s/step - loss: 0.1715 - acc: 0.9356 - val_loss: 0.3457 - val_acc: 0.8485\n",
      "Epoch 20/60\n",
      "295/295 [==============================] - 387s 1s/step - loss: 0.1830 - acc: 0.9390 - val_loss: 0.7426 - val_acc: 0.8182\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub248\n",
      "\n",
      "\n",
      "FOLD 9 results:\n",
      "TP: 16, TN: 10, FP: 1, FN: 5\n",
      "TPR: 0.7619047619047619, TNR: 0.9090909090909091, FPR: 0.09090909090909091, FNR: 0.23809523809523808\n",
      "Sensitivity/Recall: 0.7619047619047619\n",
      "Specificity: 0.9090909090909091\n",
      "Precision: 0.9411764705882353\n",
      "F1-measure: 0.8421052631578947\n",
      "Accuracy: 0.8125\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=299, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "299/299 [==============================] - 422s 1s/step - loss: 0.6431 - acc: 0.6455 - val_loss: 0.3581 - val_acc: 0.8529\n",
      "Epoch 2/60\n",
      "299/299 [==============================] - 346s 1s/step - loss: 0.4655 - acc: 0.7826 - val_loss: 0.4180 - val_acc: 0.8529\n",
      "Epoch 3/60\n",
      "299/299 [==============================] - 372s 1s/step - loss: 0.3619 - acc: 0.8562 - val_loss: 0.3575 - val_acc: 0.8529\n",
      "Epoch 4/60\n",
      "299/299 [==============================] - 360s 1s/step - loss: 0.3133 - acc: 0.8863 - val_loss: 0.6038 - val_acc: 0.8235\n",
      "Epoch 5/60\n",
      "299/299 [==============================] - 365s 1s/step - loss: 0.3645 - acc: 0.8562 - val_loss: 0.3495 - val_acc: 0.8529\n",
      "Epoch 6/60\n",
      "299/299 [==============================] - 391s 1s/step - loss: 0.3369 - acc: 0.8662 - val_loss: 0.3201 - val_acc: 0.8529\n",
      "Epoch 7/60\n",
      "299/299 [==============================] - 398s 1s/step - loss: 0.3181 - acc: 0.8863 - val_loss: 0.3501 - val_acc: 0.8824\n",
      "Epoch 8/60\n",
      "299/299 [==============================] - 385s 1s/step - loss: 0.2448 - acc: 0.9097 - val_loss: 0.3443 - val_acc: 0.8529\n",
      "Epoch 9/60\n",
      "299/299 [==============================] - 373s 1s/step - loss: 0.3317 - acc: 0.8796 - val_loss: 0.4183 - val_acc: 0.8824\n",
      "Epoch 10/60\n",
      "299/299 [==============================] - 362s 1s/step - loss: 0.2648 - acc: 0.8963 - val_loss: 0.3848 - val_acc: 0.7941\n",
      "Epoch 11/60\n",
      "299/299 [==============================] - 362s 1s/step - loss: 0.2366 - acc: 0.9130 - val_loss: 0.4596 - val_acc: 0.8824\n",
      "Epoch 12/60\n",
      "299/299 [==============================] - 362s 1s/step - loss: 0.2122 - acc: 0.9197 - val_loss: 0.2880 - val_acc: 0.8824\n",
      "Epoch 13/60\n",
      "299/299 [==============================] - 361s 1s/step - loss: 0.2372 - acc: 0.8997 - val_loss: 0.5928 - val_acc: 0.7941\n",
      "Epoch 14/60\n",
      "299/299 [==============================] - 363s 1s/step - loss: 0.1891 - acc: 0.9398 - val_loss: 0.6019 - val_acc: 0.6765\n",
      "Epoch 15/60\n",
      "299/299 [==============================] - 372s 1s/step - loss: 0.1819 - acc: 0.9398 - val_loss: 0.6447 - val_acc: 0.8824\n",
      "Epoch 16/60\n",
      "299/299 [==============================] - 408s 1s/step - loss: 0.1581 - acc: 0.9431 - val_loss: 0.5426 - val_acc: 0.7059\n",
      "Epoch 17/60\n",
      "299/299 [==============================] - 381s 1s/step - loss: 0.2049 - acc: 0.9197 - val_loss: 0.2975 - val_acc: 0.8824\n",
      "Epoch 18/60\n",
      "299/299 [==============================] - 316s 1s/step - loss: 0.1455 - acc: 0.9532 - val_loss: 0.3399 - val_acc: 0.8824\n",
      "Epoch 19/60\n",
      "299/299 [==============================] - 317s 1s/step - loss: 0.1514 - acc: 0.9431 - val_loss: 0.3570 - val_acc: 0.8824\n",
      "Epoch 20/60\n",
      "299/299 [==============================] - 322s 1s/step - loss: 0.0543 - acc: 0.9833 - val_loss: 0.3719 - val_acc: 0.8529\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub249\n",
      "\n",
      "\n",
      "FOLD 10 results:\n",
      "TP: 15, TN: 7, FP: 2, FN: 3\n",
      "TPR: 0.8333333333333334, TNR: 0.7777777777777778, FPR: 0.2222222222222222, FNR: 0.16666666666666666\n",
      "Sensitivity/Recall: 0.8333333333333334\n",
      "Specificity: 0.7777777777777778\n",
      "Precision: 0.8823529411764706\n",
      "F1-measure: 0.8571428571428571\n",
      "Accuracy: 0.8148148148148148\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=311, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "311/311 [==============================] - 384s 1s/step - loss: 0.6391 - acc: 0.6785 - val_loss: 0.3270 - val_acc: 0.8857\n",
      "Epoch 2/60\n",
      "311/311 [==============================] - 326s 1s/step - loss: 0.4726 - acc: 0.8039 - val_loss: 0.4737 - val_acc: 0.7714\n",
      "Epoch 3/60\n",
      "311/311 [==============================] - 340s 1s/step - loss: 0.4235 - acc: 0.8103 - val_loss: 0.4700 - val_acc: 0.8286\n",
      "Epoch 4/60\n",
      "311/311 [==============================] - 330s 1s/step - loss: 0.2891 - acc: 0.8939 - val_loss: 0.2641 - val_acc: 0.9143\n",
      "Epoch 5/60\n",
      "311/311 [==============================] - 338s 1s/step - loss: 0.3652 - acc: 0.8553 - val_loss: 0.3056 - val_acc: 0.8571\n",
      "Epoch 6/60\n",
      "311/311 [==============================] - 335s 1s/step - loss: 0.2329 - acc: 0.9260 - val_loss: 0.3467 - val_acc: 0.9143\n",
      "Epoch 7/60\n",
      "311/311 [==============================] - 345s 1s/step - loss: 0.2175 - acc: 0.9196 - val_loss: 1.4563 - val_acc: 0.6857\n",
      "Epoch 8/60\n",
      "311/311 [==============================] - 349s 1s/step - loss: 0.2261 - acc: 0.9003 - val_loss: 0.3082 - val_acc: 0.8857\n",
      "Epoch 9/60\n",
      "311/311 [==============================] - 320s 1s/step - loss: 0.1257 - acc: 0.9550 - val_loss: 0.8208 - val_acc: 0.8571\n",
      "Epoch 10/60\n",
      "311/311 [==============================] - 361s 1s/step - loss: 0.1543 - acc: 0.9421 - val_loss: 0.2339 - val_acc: 0.8857\n",
      "Epoch 11/60\n",
      "311/311 [==============================] - 416s 1s/step - loss: 0.1538 - acc: 0.9325 - val_loss: 0.4387 - val_acc: 0.8286\n",
      "Epoch 12/60\n",
      "311/311 [==============================] - 391s 1s/step - loss: 0.0894 - acc: 0.9678 - val_loss: 0.9853 - val_acc: 0.8286\n",
      "Epoch 13/60\n",
      "311/311 [==============================] - 369s 1s/step - loss: 0.1384 - acc: 0.9582 - val_loss: 0.1967 - val_acc: 0.9143\n",
      "Epoch 14/60\n",
      "311/311 [==============================] - 366s 1s/step - loss: 0.0907 - acc: 0.9711 - val_loss: 0.2466 - val_acc: 0.9143\n",
      "Epoch 15/60\n",
      "311/311 [==============================] - 368s 1s/step - loss: 0.0231 - acc: 0.9904 - val_loss: 0.3028 - val_acc: 0.9143\n",
      "Epoch 16/60\n",
      "311/311 [==============================] - 372s 1s/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.2639 - val_acc: 0.8857\n",
      "Epoch 17/60\n",
      "311/311 [==============================] - 309s 994ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2880 - val_acc: 0.8857\n",
      "Epoch 18/60\n",
      "311/311 [==============================] - 303s 974ms/step - loss: 9.4734e-04 - acc: 1.0000 - val_loss: 0.2780 - val_acc: 0.8857\n",
      "Epoch 19/60\n",
      "311/311 [==============================] - 296s 951ms/step - loss: 6.6810e-04 - acc: 1.0000 - val_loss: 0.2599 - val_acc: 0.8857\n",
      "Epoch 20/60\n",
      "311/311 [==============================] - 294s 944ms/step - loss: 4.7305e-04 - acc: 1.0000 - val_loss: 0.2737 - val_acc: 0.8857\n",
      "Epoch 21/60\n",
      "311/311 [==============================] - 2701s 9s/step - loss: 3.6707e-04 - acc: 1.0000 - val_loss: 0.2739 - val_acc: 0.8857\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub251\n",
      "\n",
      "\n",
      "FOLD 11 results:\n",
      "TP: 3, TN: 6, FP: 0, FN: 5\n",
      "TPR: 0.375, TNR: 1.0, FPR: 0.0, FNR: 0.625\n",
      "Sensitivity/Recall: 0.375\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "F1-measure: 0.5454545454545454\n",
      "Accuracy: 0.6428571428571429\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=311, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "311/311 [==============================] - 276s 888ms/step - loss: 0.6254 - acc: 0.6592 - val_loss: 0.7077 - val_acc: 0.7143\n",
      "Epoch 2/60\n",
      "311/311 [==============================] - 248s 797ms/step - loss: 0.6231 - acc: 0.6849 - val_loss: 0.9227 - val_acc: 0.7143\n",
      "Epoch 3/60\n",
      "311/311 [==============================] - 273s 877ms/step - loss: 0.4500 - acc: 0.8039 - val_loss: 2.7515 - val_acc: 0.6000\n",
      "Epoch 4/60\n",
      "311/311 [==============================] - 271s 871ms/step - loss: 0.4015 - acc: 0.8457 - val_loss: 0.3568 - val_acc: 0.8571\n",
      "Epoch 5/60\n",
      "311/311 [==============================] - 267s 858ms/step - loss: 0.3555 - acc: 0.8682 - val_loss: 0.4129 - val_acc: 0.8286\n",
      "Epoch 6/60\n",
      "311/311 [==============================] - 264s 848ms/step - loss: 0.3158 - acc: 0.9003 - val_loss: 1.3744 - val_acc: 0.7143\n",
      "Epoch 7/60\n",
      "311/311 [==============================] - 259s 834ms/step - loss: 0.2586 - acc: 0.9100 - val_loss: 0.9426 - val_acc: 0.7714\n",
      "Epoch 8/60\n",
      "311/311 [==============================] - 258s 828ms/step - loss: 0.1704 - acc: 0.9421 - val_loss: 0.5457 - val_acc: 0.7429\n",
      "Epoch 9/60\n",
      "311/311 [==============================] - 255s 819ms/step - loss: 0.2140 - acc: 0.9196 - val_loss: 1.7935 - val_acc: 0.8286\n",
      "Epoch 10/60\n",
      "311/311 [==============================] - 253s 813ms/step - loss: 0.2708 - acc: 0.8971 - val_loss: 0.2732 - val_acc: 0.8857\n",
      "Epoch 11/60\n",
      "311/311 [==============================] - 251s 806ms/step - loss: 0.0930 - acc: 0.9775 - val_loss: 0.4467 - val_acc: 0.8000\n",
      "Epoch 12/60\n",
      "311/311 [==============================] - 256s 822ms/step - loss: 0.2133 - acc: 0.9164 - val_loss: 0.4531 - val_acc: 0.8286\n",
      "Epoch 13/60\n",
      "311/311 [==============================] - 255s 819ms/step - loss: 0.3214 - acc: 0.8714 - val_loss: 0.6984 - val_acc: 0.6857\n",
      "Epoch 14/60\n",
      "311/311 [==============================] - 258s 829ms/step - loss: 0.1205 - acc: 0.9678 - val_loss: 0.3233 - val_acc: 0.8571\n",
      "Epoch 15/60\n",
      "311/311 [==============================] - 260s 837ms/step - loss: 0.0311 - acc: 0.9936 - val_loss: 0.3442 - val_acc: 0.8286\n",
      "Epoch 16/60\n",
      "311/311 [==============================] - 262s 841ms/step - loss: 0.1081 - acc: 0.9518 - val_loss: 0.5717 - val_acc: 0.8000\n",
      "Epoch 17/60\n",
      "311/311 [==============================] - 263s 844ms/step - loss: 0.0782 - acc: 0.9711 - val_loss: 0.3220 - val_acc: 0.8857\n",
      "Epoch 18/60\n",
      "311/311 [==============================] - 264s 850ms/step - loss: 0.1883 - acc: 0.9260 - val_loss: 0.5479 - val_acc: 0.7429\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub252\n",
      "\n",
      "\n",
      "FOLD 12 results:\n",
      "TP: 8, TN: 4, FP: 0, FN: 2\n",
      "TPR: 0.8, TNR: 1.0, FPR: 0.0, FNR: 0.2\n",
      "Sensitivity/Recall: 0.8\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "F1-measure: 0.888888888888889\n",
      "Accuracy: 0.8571428571428571\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=299, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "299/299 [==============================] - 270s 903ms/step - loss: 0.6484 - acc: 0.6455 - val_loss: 0.2742 - val_acc: 0.8824\n",
      "Epoch 2/60\n",
      "299/299 [==============================] - 238s 796ms/step - loss: 0.4925 - acc: 0.8060 - val_loss: 1.0998 - val_acc: 0.8824\n",
      "Epoch 3/60\n",
      "299/299 [==============================] - 251s 841ms/step - loss: 0.4372 - acc: 0.8328 - val_loss: 0.2431 - val_acc: 0.9412\n",
      "Epoch 4/60\n",
      "299/299 [==============================] - 254s 851ms/step - loss: 0.3852 - acc: 0.8395 - val_loss: 0.4451 - val_acc: 0.7941\n",
      "Epoch 5/60\n",
      "299/299 [==============================] - 246s 824ms/step - loss: 0.3318 - acc: 0.8595 - val_loss: 0.6312 - val_acc: 0.8235\n",
      "Epoch 6/60\n",
      "299/299 [==============================] - 248s 828ms/step - loss: 0.2618 - acc: 0.9064 - val_loss: 0.2980 - val_acc: 0.9118\n",
      "Epoch 7/60\n",
      "299/299 [==============================] - 244s 815ms/step - loss: 0.1796 - acc: 0.9465 - val_loss: 0.6658 - val_acc: 0.6765\n",
      "Epoch 8/60\n",
      "299/299 [==============================] - 246s 824ms/step - loss: 0.2433 - acc: 0.8963 - val_loss: 0.1970 - val_acc: 0.9412\n",
      "Epoch 9/60\n",
      "299/299 [==============================] - 245s 820ms/step - loss: 0.2366 - acc: 0.9164 - val_loss: 0.5834 - val_acc: 0.7941\n",
      "Epoch 10/60\n",
      "299/299 [==============================] - 243s 813ms/step - loss: 0.2209 - acc: 0.9164 - val_loss: 0.2872 - val_acc: 0.9118\n",
      "Epoch 11/60\n",
      "299/299 [==============================] - 245s 821ms/step - loss: 0.1596 - acc: 0.9498 - val_loss: 0.4731 - val_acc: 0.8824\n",
      "Epoch 12/60\n",
      "299/299 [==============================] - 244s 818ms/step - loss: 0.1822 - acc: 0.9264 - val_loss: 1.7954 - val_acc: 0.8235\n",
      "Epoch 13/60\n",
      "299/299 [==============================] - 242s 809ms/step - loss: 0.1508 - acc: 0.9398 - val_loss: 0.4429 - val_acc: 0.8529\n",
      "Epoch 14/60\n",
      "299/299 [==============================] - 243s 812ms/step - loss: 0.0628 - acc: 0.9732 - val_loss: 0.4458 - val_acc: 0.8824\n",
      "Epoch 15/60\n",
      "299/299 [==============================] - 242s 809ms/step - loss: 0.1093 - acc: 0.9599 - val_loss: 0.3470 - val_acc: 0.8824\n",
      "Epoch 16/60\n",
      "299/299 [==============================] - 243s 814ms/step - loss: 0.0952 - acc: 0.9666 - val_loss: 1.8498 - val_acc: 0.5882\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub253\n",
      "\n",
      "\n",
      "FOLD 13 results:\n",
      "TP: 5, TN: 16, FP: 1, FN: 5\n",
      "TPR: 0.5, TNR: 0.9411764705882353, FPR: 0.058823529411764705, FNR: 0.5\n",
      "Sensitivity/Recall: 0.5\n",
      "Specificity: 0.9411764705882353\n",
      "Precision: 0.8333333333333334\n",
      "F1-measure: 0.625\n",
      "Accuracy: 0.7777777777777778\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=315, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "315/315 [==============================] - 273s 867ms/step - loss: 0.6253 - acc: 0.6508 - val_loss: 0.4466 - val_acc: 0.7429\n",
      "Epoch 2/60\n",
      "315/315 [==============================] - 245s 778ms/step - loss: 0.6094 - acc: 0.6921 - val_loss: 1.6293 - val_acc: 0.4571\n",
      "Epoch 3/60\n",
      "315/315 [==============================] - 261s 830ms/step - loss: 0.4746 - acc: 0.7778 - val_loss: 3.3623 - val_acc: 0.3714\n",
      "Epoch 4/60\n",
      "315/315 [==============================] - 257s 817ms/step - loss: 0.3787 - acc: 0.8413 - val_loss: 3.0203 - val_acc: 0.3714\n",
      "Epoch 5/60\n",
      "315/315 [==============================] - 261s 829ms/step - loss: 0.3735 - acc: 0.8603 - val_loss: 0.3873 - val_acc: 0.8000\n",
      "Epoch 6/60\n",
      "315/315 [==============================] - 257s 815ms/step - loss: 0.3034 - acc: 0.8952 - val_loss: 0.6971 - val_acc: 0.6857\n",
      "Epoch 7/60\n",
      "315/315 [==============================] - 260s 825ms/step - loss: 0.2961 - acc: 0.8762 - val_loss: 0.3424 - val_acc: 0.8286\n",
      "Epoch 8/60\n",
      "315/315 [==============================] - 256s 811ms/step - loss: 0.2625 - acc: 0.8921 - val_loss: 0.6587 - val_acc: 0.7143\n",
      "Epoch 9/60\n",
      "315/315 [==============================] - 257s 815ms/step - loss: 0.3069 - acc: 0.8762 - val_loss: 0.3423 - val_acc: 0.8000\n",
      "Epoch 10/60\n",
      "315/315 [==============================] - 258s 817ms/step - loss: 0.2466 - acc: 0.9079 - val_loss: 0.2984 - val_acc: 0.8286\n",
      "Epoch 11/60\n",
      "315/315 [==============================] - 256s 811ms/step - loss: 0.2209 - acc: 0.9016 - val_loss: 0.3175 - val_acc: 0.8286\n",
      "Epoch 12/60\n",
      "315/315 [==============================] - 260s 824ms/step - loss: 0.1927 - acc: 0.9238 - val_loss: 0.3360 - val_acc: 0.8000\n",
      "Epoch 13/60\n",
      "315/315 [==============================] - 260s 826ms/step - loss: 0.1671 - acc: 0.9365 - val_loss: 0.3175 - val_acc: 0.8286\n",
      "Epoch 14/60\n",
      "315/315 [==============================] - 274s 871ms/step - loss: 0.1773 - acc: 0.9365 - val_loss: 0.3898 - val_acc: 0.8571\n",
      "Epoch 15/60\n",
      "315/315 [==============================] - 269s 855ms/step - loss: 0.2131 - acc: 0.9270 - val_loss: 0.2448 - val_acc: 0.8857\n",
      "Epoch 16/60\n",
      "315/315 [==============================] - 276s 876ms/step - loss: 0.2022 - acc: 0.9143 - val_loss: 0.2577 - val_acc: 0.8571\n",
      "Epoch 17/60\n",
      "315/315 [==============================] - 282s 894ms/step - loss: 0.1440 - acc: 0.9460 - val_loss: 0.3655 - val_acc: 0.8000\n",
      "Epoch 18/60\n",
      "315/315 [==============================] - 279s 886ms/step - loss: 0.1305 - acc: 0.9619 - val_loss: 0.3407 - val_acc: 0.8286\n",
      "Epoch 19/60\n",
      "315/315 [==============================] - 280s 888ms/step - loss: 0.0975 - acc: 0.9683 - val_loss: 0.3448 - val_acc: 0.8286\n",
      "Epoch 20/60\n",
      "315/315 [==============================] - 276s 877ms/step - loss: 0.0449 - acc: 0.9873 - val_loss: 0.2644 - val_acc: 0.8571\n",
      "Epoch 21/60\n",
      "315/315 [==============================] - 269s 855ms/step - loss: 0.0475 - acc: 0.9810 - val_loss: 0.3799 - val_acc: 0.8000\n",
      "Epoch 22/60\n",
      "315/315 [==============================] - 273s 865ms/step - loss: 0.0809 - acc: 0.9714 - val_loss: 0.3539 - val_acc: 0.8286\n",
      "Epoch 23/60\n",
      "315/315 [==============================] - 275s 873ms/step - loss: 0.1573 - acc: 0.9524 - val_loss: 0.3648 - val_acc: 0.8286\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub254\n",
      "\n",
      "\n",
      "FOLD 14 results:\n",
      "TP: 4, TN: 5, FP: 0, FN: 1\n",
      "TPR: 0.8, TNR: 1.0, FPR: 0.0, FNR: 0.2\n",
      "Sensitivity/Recall: 0.8\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "F1-measure: 0.888888888888889\n",
      "Accuracy: 0.9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=287, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "287/287 [==============================] - 269s 937ms/step - loss: 0.7080 - acc: 0.5854 - val_loss: 0.6309 - val_acc: 0.7500\n",
      "Epoch 2/60\n",
      "287/287 [==============================] - 233s 813ms/step - loss: 0.6245 - acc: 0.6760 - val_loss: 0.5797 - val_acc: 0.6875\n",
      "Epoch 3/60\n",
      "287/287 [==============================] - 248s 862ms/step - loss: 0.4618 - acc: 0.7840 - val_loss: 0.8457 - val_acc: 0.5625\n",
      "Epoch 4/60\n",
      "287/287 [==============================] - 248s 865ms/step - loss: 0.4599 - acc: 0.8153 - val_loss: 0.3129 - val_acc: 0.8750\n",
      "Epoch 5/60\n",
      "287/287 [==============================] - 236s 822ms/step - loss: 0.3673 - acc: 0.8606 - val_loss: 0.2714 - val_acc: 0.8125\n",
      "Epoch 6/60\n",
      "287/287 [==============================] - 238s 830ms/step - loss: 0.3153 - acc: 0.8815 - val_loss: 0.9241 - val_acc: 0.8125\n",
      "Epoch 7/60\n",
      "287/287 [==============================] - 240s 835ms/step - loss: 0.3308 - acc: 0.8676 - val_loss: 0.2866 - val_acc: 0.9375\n",
      "Epoch 8/60\n",
      "287/287 [==============================] - 249s 869ms/step - loss: 0.3241 - acc: 0.8746 - val_loss: 0.2030 - val_acc: 0.9375\n",
      "Epoch 9/60\n",
      "287/287 [==============================] - 251s 874ms/step - loss: 0.3049 - acc: 0.8885 - val_loss: 0.0689 - val_acc: 1.0000\n",
      "Epoch 10/60\n",
      "287/287 [==============================] - 250s 870ms/step - loss: 0.2711 - acc: 0.9059 - val_loss: 0.4521 - val_acc: 0.7500\n",
      "Epoch 11/60\n",
      "287/287 [==============================] - 255s 888ms/step - loss: 0.2918 - acc: 0.8780 - val_loss: 0.0981 - val_acc: 0.9688\n",
      "Epoch 12/60\n",
      "287/287 [==============================] - 253s 881ms/step - loss: 0.3162 - acc: 0.8606 - val_loss: 0.2237 - val_acc: 0.9375\n",
      "Epoch 13/60\n",
      "287/287 [==============================] - 238s 830ms/step - loss: 0.2206 - acc: 0.9373 - val_loss: 0.2178 - val_acc: 0.9375\n",
      "Epoch 14/60\n",
      "287/287 [==============================] - 239s 833ms/step - loss: 0.2709 - acc: 0.9059 - val_loss: 0.4214 - val_acc: 0.7188\n",
      "Epoch 15/60\n",
      "287/287 [==============================] - 237s 825ms/step - loss: 0.2861 - acc: 0.8885 - val_loss: 0.4206 - val_acc: 0.8125\n",
      "Epoch 16/60\n",
      "287/287 [==============================] - 235s 819ms/step - loss: 0.2334 - acc: 0.9164 - val_loss: 0.2264 - val_acc: 0.9062\n",
      "Epoch 17/60\n",
      "287/287 [==============================] - 237s 826ms/step - loss: 0.1998 - acc: 0.9373 - val_loss: 0.3760 - val_acc: 0.8125\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub255\n",
      "\n",
      "\n",
      "FOLD 15 results:\n",
      "TP: 13, TN: 23, FP: 2, FN: 3\n",
      "TPR: 0.8125, TNR: 0.92, FPR: 0.08, FNR: 0.1875\n",
      "Sensitivity/Recall: 0.8125\n",
      "Specificity: 0.92\n",
      "Precision: 0.8666666666666667\n",
      "F1-measure: 0.8387096774193549\n",
      "Accuracy: 0.8780487804878049\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=294, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "294/294 [==============================] - 257s 874ms/step - loss: 0.6611 - acc: 0.6463 - val_loss: 0.5856 - val_acc: 0.4545\n",
      "Epoch 2/60\n",
      "294/294 [==============================] - 230s 781ms/step - loss: 0.6181 - acc: 0.6599 - val_loss: 0.7257 - val_acc: 0.5152\n",
      "Epoch 3/60\n",
      "294/294 [==============================] - 245s 834ms/step - loss: 0.5569 - acc: 0.7415 - val_loss: 0.4295 - val_acc: 0.8788\n",
      "Epoch 4/60\n",
      "294/294 [==============================] - 261s 888ms/step - loss: 0.4593 - acc: 0.8061 - val_loss: 0.2377 - val_acc: 0.9394\n",
      "Epoch 5/60\n",
      "294/294 [==============================] - 300s 1s/step - loss: 0.5465 - acc: 0.6803 - val_loss: 0.3967 - val_acc: 0.8182\n",
      "Epoch 6/60\n",
      "294/294 [==============================] - 260s 884ms/step - loss: 0.4179 - acc: 0.8163 - val_loss: 0.2659 - val_acc: 0.9091\n",
      "Epoch 7/60\n",
      "294/294 [==============================] - 248s 844ms/step - loss: 0.3545 - acc: 0.8639 - val_loss: 0.3472 - val_acc: 0.8788\n",
      "Epoch 8/60\n",
      "294/294 [==============================] - 246s 837ms/step - loss: 0.3212 - acc: 0.8741 - val_loss: 0.5655 - val_acc: 0.7576\n",
      "Epoch 9/60\n",
      "294/294 [==============================] - 261s 887ms/step - loss: 0.3490 - acc: 0.8639 - val_loss: 0.2767 - val_acc: 0.9091\n",
      "Epoch 10/60\n",
      "294/294 [==============================] - 253s 860ms/step - loss: 0.3682 - acc: 0.8673 - val_loss: 0.2925 - val_acc: 0.8788\n",
      "Epoch 11/60\n",
      "294/294 [==============================] - 252s 859ms/step - loss: 0.3875 - acc: 0.8197 - val_loss: 0.4717 - val_acc: 0.7576\n",
      "Epoch 12/60\n",
      "294/294 [==============================] - 254s 864ms/step - loss: 0.3789 - acc: 0.8673 - val_loss: 0.4757 - val_acc: 0.8788\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub263\n",
      "\n",
      "\n",
      "FOLD 16 results:\n",
      "TP: 16, TN: 13, FP: 0, FN: 4\n",
      "TPR: 0.8, TNR: 1.0, FPR: 0.0, FNR: 0.2\n",
      "Sensitivity/Recall: 0.8\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "F1-measure: 0.888888888888889\n",
      "Accuracy: 0.8787878787878788\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=299, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "299/299 [==============================] - 278s 928ms/step - loss: 0.6402 - acc: 0.6689 - val_loss: 0.2724 - val_acc: 0.9412\n",
      "Epoch 2/60\n",
      "299/299 [==============================] - 248s 831ms/step - loss: 0.5056 - acc: 0.7592 - val_loss: 2.3759 - val_acc: 0.7353\n",
      "Epoch 3/60\n",
      "299/299 [==============================] - 261s 872ms/step - loss: 0.4166 - acc: 0.8328 - val_loss: 2.5857 - val_acc: 0.3529\n",
      "Epoch 4/60\n",
      "299/299 [==============================] - 253s 845ms/step - loss: 0.3872 - acc: 0.8662 - val_loss: 0.4932 - val_acc: 0.7647\n",
      "Epoch 5/60\n",
      "299/299 [==============================] - 249s 833ms/step - loss: 0.4560 - acc: 0.8027 - val_loss: 0.5035 - val_acc: 0.8824\n",
      "Epoch 6/60\n",
      "299/299 [==============================] - 252s 843ms/step - loss: 0.3534 - acc: 0.8662 - val_loss: 0.3293 - val_acc: 0.8824\n",
      "Epoch 7/60\n",
      "299/299 [==============================] - 253s 846ms/step - loss: 0.3333 - acc: 0.8763 - val_loss: 3.6833 - val_acc: 0.3529\n",
      "Epoch 8/60\n",
      "299/299 [==============================] - 255s 852ms/step - loss: 0.3626 - acc: 0.8562 - val_loss: 0.2943 - val_acc: 0.8824\n",
      "Epoch 9/60\n",
      "299/299 [==============================] - 256s 856ms/step - loss: 0.2985 - acc: 0.9064 - val_loss: 0.3455 - val_acc: 0.8824\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub264\n",
      "\n",
      "\n",
      "FOLD 17 results:\n",
      "TP: 9, TN: 15, FP: 3, FN: 0\n",
      "TPR: 1.0, TNR: 0.8333333333333334, FPR: 0.16666666666666666, FNR: 0.0\n",
      "Sensitivity/Recall: 1.0\n",
      "Specificity: 0.8333333333333334\n",
      "Precision: 0.75\n",
      "F1-measure: 0.8571428571428571\n",
      "Accuracy: 0.8888888888888888\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kentw\\OneDrive - University of Toronto\\PycharmProjects\\keras-kinetics-i3d\\utils.py:208: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  return Model(input=model.input, output=x)\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "c:\\users\\kentw\\appdata\\local\\continuum\\anaconda3\\envs\\keras-kinetics-i3d\\lib\\site-packages\\ipykernel_launcher.py:94: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<DataGener..., validation_data=<DataGener..., steps_per_epoch=302, class_weight={0: 1, 1: ..., callbacks=[<keras.ca..., use_multiprocessing=True, workers=6, shuffle=True, epochs=60)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "302/302 [==============================] - 279s 923ms/step - loss: 0.6480 - acc: 0.6556 - val_loss: 0.5842 - val_acc: 0.6765\n",
      "Epoch 2/60\n",
      "302/302 [==============================] - 237s 785ms/step - loss: 0.4876 - acc: 0.7815 - val_loss: 0.6112 - val_acc: 0.6765\n",
      "Epoch 3/60\n",
      "302/302 [==============================] - 251s 832ms/step - loss: 0.4665 - acc: 0.7881 - val_loss: 0.5972 - val_acc: 0.6765\n",
      "Epoch 4/60\n",
      "302/302 [==============================] - 255s 843ms/step - loss: 0.4360 - acc: 0.8079 - val_loss: 0.6511 - val_acc: 0.6765\n",
      "Epoch 5/60\n",
      "302/302 [==============================] - 253s 838ms/step - loss: 0.3144 - acc: 0.8642 - val_loss: 0.6978 - val_acc: 0.7941\n",
      "Epoch 6/60\n",
      "302/302 [==============================] - 259s 858ms/step - loss: 0.2883 - acc: 0.8775 - val_loss: 0.6701 - val_acc: 0.9118\n",
      "Epoch 7/60\n",
      "302/302 [==============================] - 255s 843ms/step - loss: 0.1852 - acc: 0.9371 - val_loss: 0.4301 - val_acc: 0.8529\n",
      "Epoch 8/60\n",
      "302/302 [==============================] - 255s 843ms/step - loss: 0.2164 - acc: 0.9139 - val_loss: 0.6970 - val_acc: 0.6765\n",
      "Epoch 9/60\n",
      "302/302 [==============================] - 250s 827ms/step - loss: 0.2650 - acc: 0.9106 - val_loss: 0.5383 - val_acc: 0.7647\n",
      "Epoch 10/60\n",
      "302/302 [==============================] - 251s 832ms/step - loss: 0.1874 - acc: 0.9503 - val_loss: 0.3562 - val_acc: 0.8235\n",
      "Epoch 11/60\n",
      "302/302 [==============================] - 257s 851ms/step - loss: 0.2189 - acc: 0.9338 - val_loss: 0.8825 - val_acc: 0.8824\n",
      "Epoch 12/60\n",
      "302/302 [==============================] - 261s 864ms/step - loss: 0.2264 - acc: 0.9238 - val_loss: 0.7805 - val_acc: 0.8824\n",
      "Epoch 13/60\n",
      "302/302 [==============================] - 251s 832ms/step - loss: 0.1512 - acc: 0.9470 - val_loss: 0.3998 - val_acc: 0.8235\n",
      "Epoch 14/60\n",
      "302/302 [==============================] - 249s 823ms/step - loss: 0.1655 - acc: 0.9536 - val_loss: 0.5004 - val_acc: 0.9412\n",
      "Epoch 15/60\n",
      "302/302 [==============================] - 251s 831ms/step - loss: 0.1144 - acc: 0.9735 - val_loss: 0.3142 - val_acc: 0.9118\n",
      "Epoch 16/60\n",
      "302/302 [==============================] - 253s 837ms/step - loss: 0.1486 - acc: 0.9536 - val_loss: 0.4860 - val_acc: 0.9118\n",
      "Epoch 17/60\n",
      "302/302 [==============================] - 250s 827ms/step - loss: 0.1335 - acc: 0.9470 - val_loss: 0.2549 - val_acc: 0.9118\n",
      "Epoch 18/60\n",
      "302/302 [==============================] - 251s 831ms/step - loss: 0.0857 - acc: 0.9669 - val_loss: 0.4662 - val_acc: 0.8824\n",
      "Epoch 19/60\n",
      "302/302 [==============================] - 248s 820ms/step - loss: 0.0390 - acc: 0.9801 - val_loss: 0.2537 - val_acc: 0.8824\n",
      "Epoch 20/60\n",
      "302/302 [==============================] - 247s 818ms/step - loss: 0.1066 - acc: 0.9702 - val_loss: 0.6374 - val_acc: 0.7647\n",
      "Epoch 21/60\n",
      "302/302 [==============================] - 252s 834ms/step - loss: 0.1851 - acc: 0.9404 - val_loss: 1.0760 - val_acc: 0.5294\n",
      "Epoch 22/60\n",
      "302/302 [==============================] - 250s 827ms/step - loss: 0.2235 - acc: 0.9305 - val_loss: 0.8020 - val_acc: 0.6765\n",
      "Epoch 23/60\n",
      "302/302 [==============================] - 249s 824ms/step - loss: 0.0951 - acc: 0.9702 - val_loss: 0.2570 - val_acc: 0.9118\n",
      "Epoch 24/60\n",
      "302/302 [==============================] - 252s 835ms/step - loss: 0.0445 - acc: 0.9801 - val_loss: 0.4752 - val_acc: 0.8529\n",
      "Epoch 25/60\n",
      "302/302 [==============================] - 249s 824ms/step - loss: 0.0881 - acc: 0.9834 - val_loss: 0.2200 - val_acc: 0.8824\n",
      "Epoch 26/60\n",
      "302/302 [==============================] - 248s 822ms/step - loss: 0.0718 - acc: 0.9735 - val_loss: 1.0394 - val_acc: 0.7059\n",
      "Epoch 27/60\n",
      "302/302 [==============================] - 254s 840ms/step - loss: 0.1377 - acc: 0.9536 - val_loss: 0.3406 - val_acc: 0.9412\n",
      "Epoch 28/60\n",
      "302/302 [==============================] - 248s 822ms/step - loss: 0.0808 - acc: 0.9801 - val_loss: 0.3497 - val_acc: 0.8824\n",
      "Epoch 29/60\n",
      "302/302 [==============================] - 247s 818ms/step - loss: 0.0121 - acc: 0.9967 - val_loss: 0.3619 - val_acc: 0.8824\n",
      "Epoch 30/60\n",
      "302/302 [==============================] - 251s 830ms/step - loss: 0.0109 - acc: 0.9967 - val_loss: 0.2695 - val_acc: 0.8824\n",
      "Epoch 31/60\n",
      "302/302 [==============================] - 249s 826ms/step - loss: 0.0058 - acc: 0.9967 - val_loss: 0.1985 - val_acc: 0.9118\n",
      "Epoch 32/60\n",
      "302/302 [==============================] - 245s 812ms/step - loss: 0.0766 - acc: 0.9868 - val_loss: 0.5894 - val_acc: 0.8529\n",
      "Epoch 33/60\n",
      "302/302 [==============================] - 249s 823ms/step - loss: 0.0306 - acc: 0.9934 - val_loss: 0.7226 - val_acc: 0.8235\n",
      "Epoch 34/60\n",
      "302/302 [==============================] - 250s 826ms/step - loss: 0.0830 - acc: 0.9702 - val_loss: 0.8430 - val_acc: 0.7647\n",
      "Epoch 35/60\n",
      "302/302 [==============================] - 248s 822ms/step - loss: 0.0806 - acc: 0.9768 - val_loss: 0.5223 - val_acc: 0.8235\n",
      "Epoch 36/60\n",
      "302/302 [==============================] - 251s 832ms/step - loss: 0.1000 - acc: 0.9702 - val_loss: 0.7898 - val_acc: 0.8824\n",
      "Epoch 37/60\n",
      "302/302 [==============================] - 252s 836ms/step - loss: 0.0200 - acc: 0.9967 - val_loss: 0.4624 - val_acc: 0.8529\n",
      "Epoch 38/60\n",
      "302/302 [==============================] - 249s 825ms/step - loss: 0.0153 - acc: 0.9967 - val_loss: 0.4100 - val_acc: 0.9118\n",
      "Epoch 39/60\n",
      "302/302 [==============================] - 252s 834ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.3134 - val_acc: 0.9118\n",
      "\n",
      "Model loaded from checkpoint\n",
      "sub265\n",
      "\n",
      "\n",
      "FOLD 18 results:\n",
      "TP: 7, TN: 11, FP: 0, FN: 6\n",
      "TPR: 0.5384615384615384, TNR: 1.0, FPR: 0.0, FNR: 0.46153846153846156\n",
      "Sensitivity/Recall: 0.5384615384615384\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "F1-measure: 0.7000000000000001\n",
      "Accuracy: 0.75\n",
      "\n",
      "\n",
      "18-FOLD CROSS-VALIDATION RESULTS ===================\n",
      "Sensitivity: nan (+/- nan)\n",
      "Specificity: 0.96 (+/- 0.07)\n",
      "FAR: 0.04 (+/- 0.07)\n",
      "MDR: nan (+/- nan)\n",
      "Accuracy: 0.83 (+/- 0.13)\n",
      "F1: nan (+/- nan)\n",
      "tp: 7.00 (+/- 5.58)\n",
      "fp: 0.56 (+/- 0.90)\n",
      "tn: 9.44 (+/- 5.59)\n",
      "fn: 3.00 (+/- 2.92)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    if not os.path.exists(best_model_path):\n",
    "        os.makedirs(best_model_path)\n",
    "    if not os.path.exists(plots_folder):\n",
    "        os.makedirs(plots_folder)\n",
    "        \n",
    "    # Experiments\n",
    "    # 1. Only with hazardous slips (with more data you gathered) --> 60:60--> same as last time with more data\n",
    "    # 2. Only with normal slips and 'no slips' --> 60:60 --> this can be a fair detection \n",
    "    # 3. Combination of 1+2 --> 120:120\n",
    "    # 4. With small slips --> 60:60\n",
    "    # 5. With all dataset --> 180:180\n",
    "    \n",
    "    experiments = {'exp1':['Hazardous_slips', 'Pass_split1'],\n",
    "                   'exp2':['Normal_slips', 'Pass_split1'],\n",
    "                   'exp3':['Hazardous_slips', 'Normal_slips', 'Pass_split1', 'Pass_split2'],\n",
    "                   'exp4':['Small_slips', 'Pass_split1'],\n",
    "                   'exp5':['Hazardous_slips', 'Normal_slips', 'Pass_split1', 'Pass_split2', 'Small_slips', 'Pass_split3']\n",
    "                  }\n",
    "    \n",
    "    main('exp5', experiments) # Make sure you change ROC manually\n",
    "    \n",
    "    # Learning rate\n",
    "    # Memory usage\n",
    "    # Patience\n",
    "    # ROC title and name\n",
    "    # Not use check model\n",
    "    # main function argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-kinetics-i3d",
   "language": "python",
   "name": "keras-kinetics-i3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
